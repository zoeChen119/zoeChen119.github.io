<!DOCTYPE html><html lang="zh-CN" data-mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="Metalearning" /><meta property="og:locale" content="zh_CN" /><meta name="description" content="Meta-Learning" /><meta property="og:description" content="Meta-Learning" /><link rel="canonical" href="https://zoechen119.github.io/posts/MetaLearning/" /><meta property="og:url" content="https://zoechen119.github.io/posts/MetaLearning/" /><meta property="og:site_name" content="zoe Chen" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2023-09-13T00:00:00+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Metalearning" /><meta name="twitter:site" content="@twitter_username" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-03-25T16:53:57+08:00","datePublished":"2023-09-13T00:00:00+08:00","description":"Meta-Learning","headline":"Metalearning","mainEntityOfPage":{"@type":"WebPage","@id":"https://zoechen119.github.io/posts/MetaLearning/"},"url":"https://zoechen119.github.io/posts/MetaLearning/"}</script><title>Metalearning | zoe Chen</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="zoe Chen"><meta name="application-name" content="zoe Chen"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="/assets/img/avatar.jfif" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">zoe Chen</a></div><div class="site-subtitle font-italic">nlper, dler, sims4er</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>首页</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>分类</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>标签</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>归档</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>关于</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/zoeChen119" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['zoe9698','163.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> 首页 </a> </span> <span>Metalearning</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> 文章</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="搜索..."> </span> <span id="search-cancel" >取消</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>Metalearning</h1><div class="post-meta text-muted"> <span> 发表于 <em class="" data-ts="1694534400" data-df="YYYY-MM-DD" data-toggle="tooltip" data-placement="bottom"> 2023-09-13 </em> </span> <span> 更新于 <em class="" data-ts="1711356837" data-df="YYYY-MM-DD" data-toggle="tooltip" data-placement="bottom"> 2024-03-25 </em> </span><div class="d-flex justify-content-between"> <span> 作者 <em> <a href="https://github.com/zoeChen119">陈政伊</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2132 字"> <em>11 分钟</em>阅读</span></div></div></div><div class="post-content"><h1 id="meta-learning">Meta-Learning</h1><h2 id="1-why-need-meta-learning"><span class="mr-2">1. Why need Meta-Learning？</span><a href="#1-why-need-meta-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="11-background"><span class="mr-2">1.1 Background</span><a href="#11-background" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>大模型在具体的工业落地中，往往需要针对每一个数据集进行训练，训练的目标是找到一个可以拟合<strong>当前数据集</strong>的函数。 <img data-src="E:/Zoe/zoeChen119.github.io/assets/img/2023-09-13-MetaLearning/2023-09-13-14-52-56.png" alt="" data-proofer-ignore> 每次都要训练，实在麻烦，那么有没有办法可以找到一个<strong>用少量样本</strong>即可拟合不同领域<strong>所有分类数据集</strong>的函数。</p><h3 id="12-what-can-meta-learning-do"><span class="mr-2">1.2. What can meta-learning do?</span><a href="#12-what-can-meta-learning-do" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><h4 id="121-plm-vs-plm--meta-learning"><span class="mr-2">1.2.1. PLM V.S. PLM + Meta Learning</span><a href="#121-plm-vs-plm--meta-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><img data-src="E:/Zoe/zoeChen119.github.io/assets/img/2023-09-13-MetaLearning/2023-09-13-14-59-51.png" alt="" data-proofer-ignore> 如图，在Task-Oriented Semantic Parsing任务中，加持了元学习（Reptile方法）之后BART的准确率恒定提升。</p><h4 id="122-mt-dnn-vs-meta-learning"><span class="mr-2">1.2.2. MT-DNN V.S. Meta Learning</span><a href="#122-mt-dnn-vs-meta-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><img data-src="E:/Zoe/zoeChen119.github.io/assets/img/2023-09-13-MetaLearning/2023-09-13-15-00-42.png" alt="" data-proofer-ignore> 如图，当训练数据越来越少，甚至少样本时，BERT的性能下降明显接近50%，MT-DNN比较稳固，但不如元学习（Reptile方法）的性能，这也佐证了元学习更适合少样本的结论。</p><h4 id="123-knowledge-distill-vs-meta-learning"><span class="mr-2">1.2.3. Knowledge Distill V.S. Meta Learning</span><a href="#123-knowledge-distill-vs-meta-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><img data-src="E:/Zoe/zoeChen119.github.io/assets/img/2023-09-13-MetaLearning/2023-09-13-15-06-48.png" alt="" data-proofer-ignore> 知识蒸馏中，有多项研究表明Teacher-Net总是能自己学的很好，但教不会Student Net，因此能否让教师网络“learn to teach”？Meta Learning可以！</p><h4 id="124-transfer-learningfine-tune-vs-meta-learning"><span class="mr-2">1.2.4. Transfer Learning/Fine-tune V.S. Meta Learning</span><a href="#124-transfer-learningfine-tune-vs-meta-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><img data-src="E:/Zoe/zoeChen119.github.io/assets/img/2023-09-13-MetaLearning/2023-09-13-15-14-00.png" alt="" data-proofer-ignore> 其实元学习和迁移学习/微调/多任务学习的界限挺模糊的，思想上很不一样，但实际上做起来好像不太好说。 比如，下面stackexchange上一位答友的<a href="https://ai.stackexchange.com/questions/18232/what-are-the-differences-between-transfer-learning-and-meta-learning">回答</a>，元学习是指“学会学习”，要学会的东西是一些更高阶的‘元知识’（超参数、初始参数等），就是你训练神经网络的工作；迁移学习是指固定一些层，剩下的层替换成新密基层，来新任务时调整新密集层的参数，在新数据集$B$上重新训练新模型。 <img data-src="E:/Zoe/zoeChen119.github.io/assets/img/2023-09-13-MetaLearning/2023-09-13-15-27-46.png" alt="" data-proofer-ignore> <img data-src="E:/Zoe/zoeChen119.github.io/assets/img/2023-09-13-MetaLearning/2023-09-13-16-28-09.png" alt="" data-proofer-ignore></p><h2 id="2-meta-learning-definition"><span class="mr-2">2. Meta-Learning Definition</span><a href="#2-meta-learning-definition" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><img data-src="E:/Zoe/zoeChen119.github.io/assets/img/2023-09-13-MetaLearning/2023-09-13-16-30-36.png" alt="" data-proofer-ignore> 机器学习是先人为调参，之后直接训练特定任务下深度模型。元学习则是先通过其它的任务训练出一个较好的超参数，然后再对特定任务进行训练。 其实就是所有在训练模型时人工设置的超参数都是元学习的目标。另一方面，元学习因为训练过程和机器学习不同，因此元学习和机器学习的数据集构造方式不一样，具体如下，在机器学习中，训练单位是样本数据，通过数据来对模型进行优化；数据可以分为训练集、测试集和验证集。在元学习中，训练单位是任务，一般有两个任务分别是训练任务（Train Tasks）亦称跨任务（Across Tasks）和测试任务（Test Task）亦称单任务（Within Task）。 <img data-src="E:/Zoe/zoeChen119.github.io/assets/img/2023-09-13-MetaLearning/2023-09-13-16-33-42.png" alt="" data-proofer-ignore></p><h2 id="3-meta-learning-application"><span class="mr-2">3. Meta-Learning Application</span><a href="#3-meta-learning-application" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><blockquote><p>Meta learning是一个通用性的方法论，Meta Learning就等价于汽车中的涡轮增压，可以应用到各种发动机中。</p></blockquote><h3 id="31-cross-domain-training"><span class="mr-2">3.1. Cross-Domain Training</span><a href="#31-cross-domain-training" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>𝒯_𝑡𝑟𝑎𝑖𝑛 和 𝒯_𝑡𝑒𝑠𝑡属于同一个NLP 问题。比如都是分类数据集。 𝒯_𝑛是不同领域，比如说𝒯_1 是通用领域文本分类数据， 𝒯_2是经济领域文本分类数据。 <img data-src="E:/Zoe/zoeChen119.github.io/assets/img/2023-09-13-MetaLearning/2023-09-13-16-38-17.png" alt="" data-proofer-ignore></p><h3 id="32-cross-question-training"><span class="mr-2">3.2. Cross-Question Training</span><a href="#32-cross-question-training" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>𝒯_𝑡𝑟𝑎𝑖𝑛 和 𝒯_𝑡𝑒𝑠𝑡属于同一领域（或相似领域）不同的NLP 问题。 𝒯_𝑛是不同问题，比如𝒯_𝑡𝑟𝑎𝑖𝑛用的是机器翻译任务和NLI任务，那么𝒯_𝑡𝑒𝑠𝑡 用的是QA和对话状态追踪（DST）。 <img data-src="E:/Zoe/zoeChen119.github.io/assets/img/2023-09-13-MetaLearning/2023-09-13-16-39-53.png" alt="" data-proofer-ignore></p><h3 id="33-domain-generalization"><span class="mr-2">3.3. Domain Generalization</span><a href="#33-domain-generalization" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>需要和跨领域训练cross-domain training区分开。Domain Generalization和Cross-Domain Training的区别也在于各个任务的数据集构造上，应用了交叉构造数据集的方法。 <img data-src="E:/Zoe/zoeChen119.github.io/assets/img/2023-09-13-MetaLearning/2023-09-13-16-41-05.png" alt="" data-proofer-ignore></p><h2 id="4-meta-learning-in-nlp"><span class="mr-2">4. Meta-Learning in NLP</span><a href="#4-meta-learning-in-nlp" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="41-learning-to-initialize"><span class="mr-2">4.1. Learning to initialize</span><a href="#41-learning-to-initialize" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>通过学习一个好的初始参数来进行快速适应新任务的方法都可以归为 learn-to-init 。MAML及其一阶近似算法（FO-MAML，Reptile，etc.） <img data-src="E:/Zoe/zoeChen119.github.io/assets/img/2023-09-13-MetaLearning/2023-09-13-16-44-10.png" alt="" data-proofer-ignore> 这个过程可以看作是构建一个适用于多个目标领域任务的内部表征，或者最大化新任务损失函数对于模型参数的敏感度。</p><h4 id="411-利用元网络meta-network来生成一个好的初始参数"><span class="mr-2">4.1.1. 利用元网络(Meta-Network)来生成一个好的初始参数</span><a href="#411-利用元网络meta-network来生成一个好的初始参数" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><img data-src="E:/Zoe/zoeChen119.github.io/assets/img/2023-09-13-MetaLearning/2023-09-13-16-45-32.png" alt="" data-proofer-ignore> 该方法强调的是“生成”。 利用元网络(Meta-Network)中的F()就是元网络，它可以根据任务数据生成初始参数，但需要针对不同的模型和任务设计不同的编码器和解码器。</p><h4 id="412-直接用元模型meta-model来学习一个好的初始参数maml"><span class="mr-2">4.1.2. 直接用元模型(Meta-Model)来学习一个好的初始参数（MAML）</span><a href="#412-直接用元模型meta-model来学习一个好的初始参数maml" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><img data-src="E:/Zoe/zoeChen119.github.io/assets/img/2023-09-13-MetaLearning/2023-09-13-16-47-16.png" alt="" data-proofer-ignore> 元模型就是指在元学习阶段被训练的模型，它可以是任何基于梯度下降算法进行训练的模型，比如CNN、LSTM、RNN及MLP等。 MAML中的F()就是元模型本身，它可以适用于任何深度学习模型和任务类型，但需要计算二阶梯度或使用一阶近似。 <img data-src="E:/Zoe/zoeChen119.github.io/assets/img/2023-09-13-MetaLearning/2023-09-13-16-49-12.png" alt="" data-proofer-ignore></p><h4 id="413-learning-to-initialize-vs-self-supervised-learning"><span class="mr-2">4.1.3. Learning to initialize V.S. Self-supervised Learning</span><a href="#413-learning-to-initialize-vs-self-supervised-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><img data-src="E:/Zoe/zoeChen119.github.io/assets/img/2023-09-13-MetaLearning/2023-09-13-16-52-09.png" alt="" data-proofer-ignore> Learning to initialize和Self-supervised Learning的区别是一个训练时带label，一个不带。</p><h4 id="414-learning-to-initialize-vs-multi-task-learning"><span class="mr-2">4.1.4. Learning to Initialize v.s. Multi-task Learning</span><a href="#414-learning-to-initialize-vs-multi-task-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><img data-src="E:/Zoe/zoeChen119.github.io/assets/img/2023-09-13-MetaLearning/2023-09-13-16-53-31.png" alt="" data-proofer-ignore> 元学习会训练一个通用的模型参数，也就是你的神经网络的初始值。当你遇到一个新的任务时，只需要用少量的样本快速适应（fast adaptation）就可以在新任务上达到很好的效果。 多任务学习会训练一个特定的网络结构，也就是你的神经网络的形式和组成。当你遇到一个新的任务时，比如识别某个数据集中的图像，你会根据这个任务和其他任务之间的关系来决定哪些参数或层要共享，哪些要分离。</p><h3 id="42-learning-to-compare"><span class="mr-2">4.2. Learning to Compare</span><a href="#42-learning-to-compare" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>通过比较任务之间的关系来进行分类。 <img data-src="E:/Zoe/zoeChen119.github.io/assets/img/2023-09-13-MetaLearning/2023-09-13-16-55-00.png" alt="" data-proofer-ignore></p><ul><li>MAML中的F()就是元模型本身，它可以适用于任何深度学习模型和任务类型，但需要计算二阶梯度或使用一阶近似。<li>learn to initialize中的F()就是元网络，它可以根据任务数据生成初始参数，但需要针对不同的模型和任务设计不同的编码器和解码器。<li>learn to compare中的F()则与其他两种方法有本质上的区别，它更像是一个分类器而不是一个元函数。 缺陷：<ol><li>learn to compare方法是一种基于已知分类的方法，它只能从支持集中已有的类别进行分类。<li>learn to compare方法需要对每个查询样本与所有支持集中的样本进行比较，这可能会导致计算量很大，尤其是在支持集较大或查询集较多的情况下。<li>learn to compare方法只考虑了单个查询样本与单个支持集样本之间的相似度，而没有考虑整个查询集与整个支持集之间的全局信息。<li>learn to compare方法依赖于一个有效的相似度计算模块，它需要能够捕捉不同任务或类别之间的语义或逻辑关系。然而，这种相似度计算模块可能很难设计或训练，尤其是在一些复杂或多样化的领域中。</ol></ul><h2 id="5-meta-learning-in-specific-domain"><span class="mr-2">5. Meta-Learning in Specific Domain</span><a href="#5-meta-learning-in-specific-domain" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>呼应开头的第一张图，现在我们的目标是训练一个优秀的元学习算法！~ <img data-src="E:/Zoe/zoeChen119.github.io/assets/img/2023-09-13-MetaLearning/2023-09-13-16-59-12.png" alt="" data-proofer-ignore></p><h2 id="reference"><span class="mr-2">Reference</span><a href="#reference" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>论文：</p><ol><li>Lee, H.-Y., Li, S.-W., Vu, N., n.d. Meta Learning for Natural Language Processing: A Survey.<li>Yue, Z., Zeng, H., Zhang, Y., Shang, L., Wang, D., 2023. MetaAdapt: Domain Adaptive Few-Shot Misinformation Detection via Meta Learning.<li>Lu, M., Huang, Z., Zhao, Y., Tian, Z., Li, Y., 2023. DaMSTF: Domain Adversarial Learning Enhanced Meta Self-Training for Domain Adaptation.<li>Qin, C., Joty, S., Li, Q., Zhao, R., 2023. Learning to Initialize: Can Meta Learning Improve Cross-task Generalization in Prompt Tuning?<li>Antoniou, A., Edwards, H., Storkey, A., 2018. How to train your MAML. International Conference on Learning Representations,International Conference on Learning Representations.<li>Sun, Q., Liu, Y., Chua, T.-S., Schiele, B., 2019. Meta-Transfer Learning for Few-Shot Learning., in: 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). https://doi.org/10.1109/cvpr.2019.00049<li>Behl, H., Baydin, A., Torr, PhilipH.S., 2019. Alpha MAML: Adaptive Model-Agnostic Meta-Learning. Cornell University - arXiv,Cornell University - arXiv.<li>Liu, Z., Zhang, R., Song, Y., Zhang, M., 2020. When does MAML Work the Best? An Empirical Study on Model-Agnostic Meta-Learning in NLP Applications. Cornell University - arXiv,Cornell University - arXiv.</ol><p>课程： <a href="https://www.youtube.com/watch?v=EkAqYbpCYAc&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=32">Meta Learning –Hung-yi Lee- YouTube</a> <a href="https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.php">ML 2021 Spring (ntu.edu.tw)</a> <a href="https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php">ML 2022 Spring (ntu.edu.tw)</a></p><p>博客：</p><ol><li><a href="https://zhuanlan.zhihu.com/p/614026548">Few-shot Learning（五）Learning to Compare: Relation Network for Few-Shot Learning - 知乎 (zhihu.com)</a><li><a href="https://www.cnblogs.com/BlairGrowing/p/17652322.html">论文解读（MetaAdapt）《MetaAdapt: Domain Adaptive Few-Shot Misinformation Detection via Meta Learning》 - Wechat~Y466551 - 博客园 (cnblogs.com)</a><li><a href="https://ai.stackexchange.com/questions/18232/what-are-the-differences-between-transfer-learning-and-meta-learning">What are the differences between transfer learning and meta learning? - Artificial Intelligence Stack Exchange</a><li><a href="https://meta-learning.fastforwardlabs.com/#why-should-we-care%3F">Meta-Learning (fastforwardlabs.com)</a><li><div class="table-wrapper"><table><tbody><tr><td>[Meta-Learning: Learning to Learn. Although artificial intelligence and…<td>by Thomas HARTMANN<td>DataThings<td>Medium](https://medium.com/datathings/meta-learning-learning-to-learn-a55cadd32b17)</table></div></ol></div><div class="post-tail-wrapper text-muted"><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> 本文由作者按照 <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> 进行授权</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">分享</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Metalearning+-+zoe+Chen&url=https%3A%2F%2Fzoechen119.github.io%2Fposts%2FMetaLearning%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Metalearning+-+zoe+Chen&u=https%3A%2F%2Fzoechen119.github.io%2Fposts%2FMetaLearning%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fzoechen119.github.io%2Fposts%2FMetaLearning%2F&text=Metalearning+-+zoe+Chen" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="分享链接" data-title-succeed="链接已复制！"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">最近更新</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/C25_11%E5%85%A5%E9%97%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%860/">【NLP入门趣味题】肉眼找朋友</a><li><a href="/posts/C25_11%E5%85%A5%E9%97%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%861/">【NLP入门趣味题】探索语言模型与词向量</a><li><a href="/posts/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/">强化学习</a><li><a href="/posts/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AE%9E%E9%AA%8C/">多模态实验</a><li><a href="/posts/%E5%A4%9A%E6%A8%A1%E6%80%81RAG/">多模态rag</a></ul></div><div id="access-tags"><div class="panel-heading">热门标签</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/nlp/">nlp</a> <a class="post-tag" href="/tags/%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/">技术综述</a> <a class="post-tag" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a> <a class="post-tag" href="/tags/rag/">RAG</a> <a class="post-tag" href="/tags/%E8%AF%AD%E8%A8%80%E5%AD%A6/">语言学</a> <a class="post-tag" href="/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/">预训练模型</a> <a class="post-tag" href="/tags/bert/">BERT</a> <a class="post-tag" href="/tags/courses/">Courses</a> <a class="post-tag" href="/tags/chatgpt/">ChatGPT</a> <a class="post-tag" href="/tags/mamba/">Mamba</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">文章内容</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>相关文章</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/C25_11%E5%85%A5%E9%97%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%861/"><div class="card-body"> <em class="small" data-ts="1746514856" data-df="YYYY-MM-DD" > 2025-05-06 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>【NLP入门趣味题】探索语言模型与词向量</h3><div class="text-muted small"><p> 【NLP入门趣味题】探索语言模型与词向量 题目名称： “猜猜我是谁？——用词向量玩文字游戏” 🎯 任务目标 理解语言模型（Language Model）的基本概念——它能预测下一个词是什么！ 认识词向量（Word Embedding）——让计算机”看懂”词语的数学表达。 通过简单代码体验语义相似度，感受AI如何理解词语关系。 🔍 题目内容 假设你有一个超级简单的...</p></div></div></a></div><div class="card"> <a href="/posts/C25_11%E5%85%A5%E9%97%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%860/"><div class="card-body"> <em class="small" data-ts="1745910056" data-df="YYYY-MM-DD" > 2025-04-29 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>【NLP入门趣味题】肉眼找朋友</h3><div class="text-muted small"><p> 【NLP入门趣味题】肉眼找朋友 ❓ 问题1：肉眼找朋友 观察坐标，回答以下问题（无需计算）： “国王” 和 “王后” 的距离近，还是 “苹果” 和 “香蕉” 的距离近？ 如果 “国王” 的坐标是 (1, 0)，你觉得 “王子” 的坐标可能是？ A. (0.8, 0.2) B. (0, 0.8) 💡 提示：第一个数字代表...</p></div></div></a></div><div class="card"> <a href="/posts/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AE%9E%E9%AA%8C/"><div class="card-body"> <em class="small" data-ts="1739203200" data-df="YYYY-MM-DD" > 2025-02-11 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>多模态实验</h3><div class="text-muted small"><p> 多模态实验过程记录 实验1：colpaligemma-3b-pt-448-base测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/Elsevier-%E6%9C%9F%E5%88%8A%E6%8A%95%E7%A8%BF%E8%B8%A9%E5%9D%91/" class="btn btn-outline-primary" prompt="上一篇"><p>Elsevier 期刊投稿踩坑</p></a> <a href="/posts/BAAI%E5%90%91%E9%87%8F%E6%A8%A1%E5%9E%8BBGE/" class="btn btn-outline-primary" prompt="下一篇"><p>Baai向量模型bge</p></a></div><script src="https://utteranc.es/client.js" repo="zoeChen119/zoeChen119.github.io" issue-term="title" crossorigin="anonymous" async> </script> <script type="text/javascript"> $(function() { const origin = "https://utteranc.es"; const iframe = "iframe.utterances-frame"; const lightTheme = "github-light"; const darkTheme = "github-dark"; let initTheme = lightTheme; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches)) { initTheme = darkTheme; } addEventListener("message", (event) => { let theme; /* credit to <https://github.com/utterance/utterances/issues/170#issuecomment-594036347> */ if (event.origin === origin) { /* page initial */ theme = initTheme; } else if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { /* global theme mode changed */ const mode = event.data.message; theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme); } else { return; } const message = { type: "set-theme", theme: theme }; const utterances = document.querySelector(iframe).contentWindow; utterances.postMessage(message, origin); }); }); </script></div></div><footer class="row pl-3 pr-3"><div class="col-12 d-flex justify-content-between align-items-center text-muted pl-0 pr-0"><div class="footer-left"><p class="mb-0"> © 2025 <a href="https://github.com/zoeChen119">陈政伊</a>. <span data-toggle="tooltip" data-placement="top" title="除非另有说明，本网站上的博客文章均由作者按照知识共享署名 4.0 国际 (CC BY 4.0) 许可协议进行授权。">保留部分权利。</span></p></div><div class="footer-right"><p class="mb-0"> 本站由 <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> 生成，采用 <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> 主题。</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">热门标签</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/nlp/">nlp</a> <a class="post-tag" href="/tags/%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/">技术综述</a> <a class="post-tag" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a> <a class="post-tag" href="/tags/rag/">RAG</a> <a class="post-tag" href="/tags/%E8%AF%AD%E8%A8%80%E5%AD%A6/">语言学</a> <a class="post-tag" href="/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/">预训练模型</a> <a class="post-tag" href="/tags/bert/">BERT</a> <a class="post-tag" href="/tags/courses/">Courses</a> <a class="post-tag" href="/tags/chatgpt/">ChatGPT</a> <a class="post-tag" href="/tags/mamba/">Mamba</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">发现新版本的内容。</p><button type="button" class="btn btn-primary" aria-label="Update"> 更新 </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">搜索结果为空</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/zh.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
