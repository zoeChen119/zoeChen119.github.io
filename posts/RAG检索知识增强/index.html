<!DOCTYPE html><html lang="zh-CN" data-mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="RAG" /><meta property="og:locale" content="zh_CN" /><meta name="description" content="RAG检索知识增强 不完全手册" /><meta property="og:description" content="RAG检索知识增强 不完全手册" /><link rel="canonical" href="https://zoechen119.github.io/posts/RAG%E6%A3%80%E7%B4%A2%E7%9F%A5%E8%AF%86%E5%A2%9E%E5%BC%BA/" /><meta property="og:url" content="https://zoechen119.github.io/posts/RAG%E6%A3%80%E7%B4%A2%E7%9F%A5%E8%AF%86%E5%A2%9E%E5%BC%BA/" /><meta property="og:site_name" content="zoe Chen" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2024-02-21T00:00:00+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="RAG" /><meta name="twitter:site" content="@twitter_username" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-02-21T00:00:00+08:00","datePublished":"2024-02-21T00:00:00+08:00","description":"RAG检索知识增强 不完全手册","headline":"RAG","mainEntityOfPage":{"@type":"WebPage","@id":"https://zoechen119.github.io/posts/RAG%E6%A3%80%E7%B4%A2%E7%9F%A5%E8%AF%86%E5%A2%9E%E5%BC%BA/"},"url":"https://zoechen119.github.io/posts/RAG%E6%A3%80%E7%B4%A2%E7%9F%A5%E8%AF%86%E5%A2%9E%E5%BC%BA/"}</script><title>RAG | zoe Chen</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="zoe Chen"><meta name="application-name" content="zoe Chen"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="/assets/img/avatar.jfif" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">zoe Chen</a></div><div class="site-subtitle font-italic">nlper, dler, sims4er</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>首页</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>分类</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>标签</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>归档</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>关于</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/zoeChen119" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['zoe9698','163.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> 首页 </a> </span> <span>RAG</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> 文章</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="搜索..."> </span> <span id="search-cancel" >取消</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>RAG</h1><div class="post-meta text-muted"> <span> 发表于 <em class="" data-ts="1708444800" data-df="YYYY-MM-DD" data-toggle="tooltip" data-placement="bottom"> 2024-02-21 </em> </span><div class="d-flex justify-content-between"> <span> 作者 <em> <a href="https://github.com/zoeChen119">陈政伊</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="6306 字"> <em>35 分钟</em>阅读</span></div></div></div><div class="post-content"><h1 id="rag检索知识增强-不完全手册">RAG检索知识增强 不完全手册</h1><p><img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJgGjh6IllvTWYL5bONOuQQOLOlxwvXgJGy9pVzd8LMxP2uibBtlV1icSAnCw3wRYL8tXPhPTXDGaQ/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" data-proofer-ignore></p><p>本文从k个角度对RAG技术进行综述，第一个角度是“范式演变”，即原始的“朴素RAG”-“进阶RAG”-“模块化RAG”，这个角度个人认为是工程的角度、宏观的角度；第二个角度是“关键问题和相关研究”，大类上可分两类“以优化生成模型的表征空间为目的”和“以优化知识密集型问答任务为目的”。</p><p>通常“以优化生成模型的表征空间为目的”的这些模型有几个特点：（1）检索对象是token/chunk，即取input中的部分或全部token作为query触发检索器，（2）检索的时机是每生成1个token都要增强一下，这样才能达到优化整个表征空间的目的，（3）使用检索内容的方式既可以在输入层注入、在生成模型内部注入也可以在输出层注入。</p><p>通常“以优化知识密集型问答任务为目的”的这些模型有几个特点：（1）检索对象下至token-level上至段落-level，（2）检索的时机多为隔几个token或者遇见特定的token才会触发检索，因为它的目的不是优化表征空间，而是优化问答任务，(3）使用检索内容的方式往往不采用在生成模型内部注入的方法，因为这种模型往往不希望训练。</p><p>[1] 专补大模型短板的RAG有哪些新进展？这篇综述讲明白了https://mp.weixin.qq.com/s/yZo-HcGuWFQE8B63hZkqVQ</p><div class="table-wrapper"><table><tbody><tr><td>[2] 前沿重器[41]<td>综述-面向大模型的检索增强生成（RAG）https://mp.weixin.qq.com/s/Ebc-DEpfEBNP1nrQHkQv4g</table></div><p>[3] OpenAI Sora、Prompt工程、RAG、表格处理、长文本、embedding等大模型进展总结分享回顾https://mp.weixin.qq.com/s/5nUKrTYSGrJhPMIXw6_35A</p><p>[4] 大模型如何可解释？帝国理工最新《大型语言模型的解释性》最新综述https://mp.weixin.qq.com/s/kW5qpJQQ74wo8LfiiGgeCA</p><p>[5] 大模型增量预训练新技巧-解决灾难性遗忘https://mp.weixin.qq.com/s/IoCxatkaDeYhfWVuCQKnJw</p><p>[6] 说说我对RAG技术的理解https://mp.weixin.qq.com/s/7FH7sqk3pc2hjH-bkGtHxg</p><p>[7] Transformer的无限之路：位置编码视角下的长度外推综述https://mp.weixin.qq.com/s/9SK8YuUzHr4ZOnFkQNQb6g</p><p>[8] TRL 正式推出，来训练你的首个 RLHF 模型吧！https://mp.weixin.qq.com/s/WSUs0ipdb2gKkNdQ60isRw</p><div class="table-wrapper"><table><tbody><tr><td>[9] 分享<td> <td>OpenAI 如何不通过 fine-tuning 将 <strong>RAG</strong> 的准确率由 45% 提升至 98%？https://mp.weixin.qq.com/s/B7VaDU02LIC5x_ww3zlb2A</table></div><p>[10] <strong>RAG</strong>的究极进化：知识图谱和向量检索结合https://mp.weixin.qq.com/s/Q-Dtq-sFgsJQI4r7C4lr4Q</p><p>[11] 简单提升<strong>RAG</strong>的10种方法https://mp.weixin.qq.com/s/bNyMMDkjPWOq_V1AqHqCBg</p><p>[12]【图文长文】探索<strong>RAG</strong>技术：从知识检索到答案生成的神奇过程解析https://mp.weixin.qq.com/s/qaEEMUxstAjVKml7VbfqFA</p><p>[13] <strong>RAG</strong>行业交流中发现的一些问题和改进方法https://mp.weixin.qq.com/s/BXP3g8El3jUF8VFjh3Ufzg</p><p>[14] ChatGPT应用：如何征服市场眼中的“万能<strong>RAG</strong>”https://mp.weixin.qq.com/s/4kwwBnpGvXbwNBatLqcghg</p><p>[15] Graph <strong>RAG</strong>: 知识图谱结合 LLM 的检索增强 - 知乎https://zhuanlan.zhihu.com/p/654008500</p><p>[16] <strong>基于RAG构建生成式AI应用</strong>最佳实践与“避坑指南”–亚马逊https://github.com/lizhe2004/Awesome-LLM-RAG-Application/blob/main/resource</p><p>[17] 爱可可 AI 前沿推介(8.10)https://mp.weixin.qq.com/s/VqjlUeji1PAsF9PEKy4oYQ</p><h2 id="一范式演变"><span class="mr-2">一、范式演变</span><a href="#一范式演变" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><img data-src="F:\KDGC4年上半年-RAG\调研\RAG范式演变-流程图.png" alt="图片" data-proofer-ignore></p><p>[1]【RAG系列探索之旅·第四弹】RAG研究范式：从初级到高级的演变https://mp.weixin.qq.com/s/VHHmn2DDZ_ykSxdFNsK9vg</p><p>[2]【RAG系列探索之旅·第六弹】模块化RAG：重塑信息检索的未来https://mp.weixin.qq.com/s/FX4zs3GbIFIhtG4O3b6dNg</p><div class="table-wrapper"><table><tbody><tr><td>[3] 技术动态<td>模块化（Modular）RAG 和 RAG Flowhttps://mp.weixin.qq.com/s/Pdx8J_tCyYJ_bgFknc4UoA</table></div><p>[4] 也看大模型RAG长文本任务中的上下文精简与构造方式：兼看最近一周的大模型开源工作https://mp.weixin.qq.com/s/6RrFxfcj0w7jhPXk5mqEuw</p><h3 id="11-naive-rag"><span class="mr-2">1.1 Naive RAG</span><a href="#11-naive-rag" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><h4 id="局限性"><span class="mr-2">局限性：</span><a href="#局限性" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><ol><li>检索——不够准确<ul><li>精度低：检索块错位<li>召回率低：无法检索所有相关块<li>信息过时：产生不准确的检索结果</ul><li>生成——幻觉、可控性差<ul><li>生成的答案不基于检索到的文档<li>生成的答案与问题上下文不相关<li>生成的答案存在潜在反事实错误或偏见</ul><li>增强——如何更好的融合外部文档<ul><li>多个检索段包含相似信息时，生成的响应中会出现重复内容<li>多个检索段的重要性和相关性，对答案生成的价值需要平衡好<li>模型过度依赖检索段的信息，导致输出的只是重复检索的内容，而不提供新的价值或合成信息</ul></ol><h3 id="12-advanced-rag"><span class="mr-2">1.2 Advanced RAG</span><a href="#12-advanced-rag" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><h4 id="121-pre-retrieval-process"><span class="mr-2">1.2.1 Pre-Retrieval Process</span><a href="#121-pre-retrieval-process" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>优化检索器的输出质量：</p><ul><li><p><strong>数据清洗与更新</strong>：删除不相关的信息，消除实体和术语中的歧义，确认事实的准确性，维护上下文，以及更新过时的文件。</p><li><p><strong>优化文档结构</strong>：调整块的大小以捕获相关上下文，跨多个索引路径进行查询，以及通过利用图数据索引中节点之间的关系来合并来自图结构的信息以捕获相关的上下文。</p><li><p><strong>添加元数据信息</strong>：将引用的元数据（如日期和目的）集成到块中以进行过滤，并合并引用的章节和小节等元数据以提高检索效率。</p><li><p><strong>对齐优化</strong>：对问题进行重写、路由和扩充。通过在文档中引入“假设问题”[Li et al.，2023d]来纠正对齐问题和差异，从而解决对齐问题和文档之间的差异。</p></ul><h4 id="122-post-retrieval-process"><span class="mr-2">1.2.2 Post-Retrieval Process</span><a href="#122-post-retrieval-process" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>从数据库中检索到有价值的上下文后，必须将其与查询合并，作为LLM的输入，同时解决上下文窗口限制带来的挑战。简单地将所有相关文档一次性呈现给LLM可能会超出上下文窗口限制，引入噪声，并阻碍对关键信息的关注。为了解决这些问题，需要对检索到的内容进行额外的处理。</p><ul><li><strong>重排序</strong>：对检索到的信息重新排序以将最相关的内容重新定位到提示的边缘是一个关键策略，避免 “Lost in the Middle ” 现象的发生。<li><strong>Prompt 压缩</strong>：检索到的文档中的噪声会对RAG性能产生不利影响。在后处理中，重点在于压缩不相关的上下文，突出关键段落，减少整体上下文长度。</ul><h3 id="13-modular-rag"><span class="mr-2">1.3 Modular RAG</span><a href="#13-modular-rag" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240305165849428.png" alt="image-20240305165849428" data-proofer-ignore></p><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240228102155256.png" alt="image-20240228102155256" data-proofer-ignore></p><p>部分模块介绍：</p><ol><li><p>记忆池模块</p><p>在<strong>检索增强生成（RAG）</strong>中，记忆池和检索到的外部知识文档的区别。</p><p><strong>记忆池</strong>：</p><p>​ 1.<strong>定义</strong>：记忆池是一个存储在模型内部的数据集合，用于引导模型的生成过程。</p><p>​ 2.<strong>数据来源</strong>：记忆池中的数据通常来自于模型训练时使用的数据集，或者是与任务相关的其他文本片段。</p><p>​ 3.<strong>特点</strong>：这些数据是模型已经学到的知识，存储在模型的权重中（参数记忆）。</p><p>​ 4.<strong>更新</strong>：记忆池的数据通常不会频繁更新，因为它们是模型训练期间获取的。</p><p><strong>检索到的外部知识文档</strong>：</p><p>​ 1.<strong>定义</strong>：这些文档是从外部知识源（例如向量数据库、专业领域的文章等）中检索到的数据。</p><p>​ 2.<strong>数据来源</strong>：外部知识文档可能包含最新的、专有的、或特定领域的信息。</p><p>​ 3.<strong>特点</strong>：这些文档不是模型训练期间学到的，而是从外部获取的，因此可能更准确、更具体。</p><p>​ 4.<strong>更新</strong>：外部知识文档可以随时更新，而不会产生重大成本。</p><p>总之，记忆池是模型已知的内部数据，而检索到的外部知识文档是从外部获取的数据。RAG通过结合这两者，使模型能够更准确地生成答案，并且可以利用最新的、来自外部的信息。</p><li><p>融合模块</p><p>通过多查询的方式扩展用户查询，从不同角度获取信息，确保搜索结果与用户的显性和隐性意图密切相关，从而实现更深入、更准确的信息发现。</p><ol><li><p><strong>RAG-Fusion</strong>：这个方法通过多查询的方式扩展用户查询，从不同角度获取信息，利用<strong>语言模型</strong>（LLM）来揭示更深层次、变革性的知识。具体而言，它包括以下步骤：</p><ul><li><strong>扩展查询</strong>：将用户查询扩展为多个不同的视角，以获取更全面的信息。<li><strong>并行向量搜索</strong>：同时对原始查询和扩展查询进行向量搜索，以获取相关文档。<li><strong>智能重新排序</strong>：对搜索结果进行智能排序，以优化答案的质量。<li><strong>新查询匹配</strong>：将最佳结果与新查询匹配，以满足用户的显性和隐性意图。</ul><li><p><strong>优势与挑战</strong>：</p><ul><li><p>优势：</p><ul><li><strong>实时更新</strong>：RAG能够访问最新的外部信息，保持知识的时效性。<li><strong>减少幻觉</strong>：通过使用外部验证信息，RAG有助于减少语言模型产生的错误或虚构信息。<li><strong>高透明度</strong>：生成答案时引用外部信息源，增加可信度和可追溯性。</ul><li><p>挑战：</p><ul><li><strong>外部依赖</strong>：RAG的性能高度依赖于外部知识库的质量和覆盖范围。<li><strong>生成延迟</strong>：检索过程可能增加回答生成的时间延迟。</ul></ul></ol><li><p>路由模块</p><p>负责决定对用户查询的后续操作。</p><ol><li><strong>数据源处理决策</strong>：RAG系统的检索过程利用了不同领域、不同语言和不同格式的多样化数据源。路由模块决定对这些数据源如何操作比如交替或合并。<li><strong>查询处理决策</strong>：<ul><li><strong>摘要生成</strong>：查询路由器决定是否提供相关信息的简洁摘要。<li><strong>数据库搜索</strong>：路由模块决定连接到哪个特定数据库，以获取详细的信息。<li><strong>路径合并</strong>：路由模块决定是否将不同路径的信息合并为单个响应。</ul><li><strong>数据存储方式决策</strong>：查询路由器还会选择适当的数据存储方式，这可能包括各种来源，如向量存储、图数据库、关系数据库或索引层次结构，例如用于多文档存储的摘要索引和文档块向量索引。查询路由器的决策是预定义的，并通过语言模型（LLMs）调用来执行，从而将查询定向到选择的索引。</ol><li><p>预测模块</p><p>不直接从数据源检索内容，而是利用语言模型（LLM）生成必要的上下文。这个上下文包含了与用户查询相关的信息。这个上下文被当作query执行检索。</p><p>好处： ​ 1. 减少冗余：由LLM生成的内容更有可能包含相关信息，相比直接从数据源检索获得的内容更具相关性。因此，它可以减少重复的信息。 ​ 2. 降低噪音：通过使用LLM生成的上下文，预测模块可以过滤掉不相关或低质量的信息**，从而减少了检索结果中的噪音。</p><li><p>适配器模块</p><p>两个例子：</p><p>UPRISE：这个模块自动从预先构建的数据池中检索用于零样本任务输入的提示。通过这种方式，它增强了任务和模型之间的通用性。UPRISE使得RAG能够适应不同任务的需求，而无需重新训练模型。 PROMPTAGATOR：这个模块利用语言模型（LLM）作为少样本查询生成器。基于生成的数据，它创建了特定任务的检索器。通过充分利用LLMs的泛化能力，PROMPTAGATOR可以使用极少的示例开发特定任务的端到端检索器。</p></ol><h2 id="二rag的3大关键问题"><span class="mr-2">二、RAG的3大关键问题</span><a href="#二rag的3大关键问题" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><font color="DarkGreen">**解决关键问题的方法其实是在优化RAG中的1或多个模块的方法。**</font><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240305170031250.png" alt="image-20240305170031250" data-proofer-ignore></p><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240305170110729.png" alt="image-20240305170110729" data-proofer-ignore></p><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240305170136264.png" alt="image-20240305170136264" data-proofer-ignore></p><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240305170150241.png" alt="image-20240305170150241" data-proofer-ignore></p><p>[1] Advanced RAG — Improving retrieval using Hypothetical Document Embeddings(HyDE):https://medium.aiplanet.com/advanced-rag-improving-retrieval-using-hypothetical-document-embeddings-hyde-1421a8ec075a</p><p>[2] 一文纵览LLM+RAG 的方法实现https://mp.weixin.qq.com/s/ifp2i71Psn86ZCEzffsF0Q</p><p>[3] 大模型检索增强生成（RAG）系统进化指南https://mp.weixin.qq.com/s/4Ttd3hi13B4VdoPGauwMzA</p><div class="table-wrapper"><table><tbody><tr><td>[4] ACL23<td>基于检索的大语言模型-陈丹琦报告阅读https://mp.weixin.qq.com/s/_rajDkg-T1a6R0MKlLSEXA</table></div><p>[5] RAG Survey - 三大组件https://mp.weixin.qq.com/s/W1E_qFajK6XJYRNzlriS6Q</p><p>[6] ACL 2023 Tutorial: Retrieval-based LMs and Applicationshttps://acl2023-retrieval-lm.github.io/</p><h3 id="41-优化生成模型表征空间"><span class="mr-2">4.1 优化生成模型表征空间</span><a href="#41-优化生成模型表征空间" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>每隔l个token触发1次检索，第t次生成是根据当前片段$window_t$以及其对应的最相似文档$R(window_t)$生成的。</p><h5 id="-retro"><span class="mr-2">① RETRO</span><a href="#-retro" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h5><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240222110340403.png" alt="image-20240222110340403" data-proofer-ignore></p><p>RETRO模型是每隔l个token触发一次检索，检索器的输入q是当前的上下文片段，然后根据q检索出k个最相似的文档片段，作为检索器的输出retriever(q)。然后，第t次生成的输出yt是由语言模型LM根据q和retriever(q)的联合表示来预测的。也就是说，yt=RETRO-block(qt,retriever(qt)]是RETRO模型的生成公式。</p><p><code class="language-plaintext highlighter-rouge">公式</code></p><h5 id="-ic-ralm"><span class="mr-2">② IC-RALM</span><a href="#-ic-ralm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h5><p>算是一种适应性检索。</p><blockquote><p>Since common Transformer-based LM implementations support limited length input sequences, when the concatenation of the document and the input sequence exceed this limit we remove tokens from the beginning of x until the overall input length equals that allowed by the model. Because our retrieved documents are passages of limited length, we always have enough context left from x.</p></blockquote><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240221105434785.png" alt="image-20240221105434785" data-proofer-ignore></p><p><a href="https://zhuanlan.zhihu.com/p/674085535">IC-RALM是一种检索增强语言模型，它使用一个可训练的检索器来动态地调整检索到的文档的权重，以适应不同的任务</a><a href="https://zhuanlan.zhihu.com/p/674085535">1</a>。它的主要思想是将检索到的文档作为上下文，与当前的生成状态一起输入到语言模型中，从而提高生成的质量和多样性。它的主要优点是<strong>可以根据任务的需求，自动选择最相关的文档，并且可以处理多个文档的组合</strong>。它的主要缺点是需要对检索器和语言模型进行联合训练，这会增加计算成本和复杂性。</p><p>IC-RALM的工作流程如下：</p><ul><li>首先，给定一个输入序列，例如一个问题或一个部分生成的文本，检索器会从一个大型的文档集合中检索出k个最相关的文档。检索器可以是任何基于向量的检索方法，例如BM25、DPR或ColBERT。<li>然后，<strong>检索器会为每个检索到的文档分配一个权重，表示它对当前输入的重要性</strong>。<strong>权重是通过一个可训练的神经网络计算的</strong>，该网络接收检索到的文档和输入序列的嵌入作为输入，并输出一个标量值。权重可以被视为一个注意力机制，用于选择最相关的文档。<li>接下来，检索到的文档和输入序列被拼接在一起，形成一个新的输入序列，用于语言模型的生成。语言模型可以是任何基于Transformer的自回归模型，例如GPT-2或GPT-3。语言模型会根据检索到的文档和输入序列生成下一个标记，从而实现文本生成或问答等任务。<li>最后，<strong>检索器和语言模型会通过反向传播进行联合训练，以最小化生成标记的交叉熵损失。</strong>这样，检索器可以学习如何为不同的任务选择最合适的文档，而语言模型可以学习如何利用检索到的文档进行更好的生成。</ul><h5 id="-knnlm"><span class="mr-2">③ KNNLM</span><a href="#-knnlm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h5><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240222113505272.png" alt="image-20240222113505272" data-proofer-ignore></p><p>KNN-LM在生成模型根据上文生成下一个token的时候，将上文的向量表征和训练集中的所有上文的表征进行knn计算，得到最相近的k个上文各自的下一个token，归一化，和原来的下一个token计算，得到一个更优的下一个token。</p><p>每个token检索1次。</p><h5 id="-replug"><span class="mr-2">④ REPLUG</span><a href="#-replug" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h5><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240305161124459.png" alt="image-20240305161124459" data-proofer-ignore></p><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240305161204660.png" alt="image-20240305161204660" data-proofer-ignore></p><div class="table-wrapper"><table><tbody><tr><td>[1] 论文分享<td>arXiv-23<td>REPLUG：检索增强黑盒语言模型https://mp.weixin.qq.com/s/cS3eTDSO1oDs8hSxMkTjvw</table></div><p>[2] 一文详解检索增强语言模型新范式REPLUGhttps://mp.weixin.qq.com/s/kULpBme-NSYmOw4RLboyGQ</p><p>[3] REPLUG: Retrieval-Augmented Black-Box Language Modelshttps://readpaper.com/pdf-annotate/note?pdfId=4762336033991819265</p><p>[4] 大模型RAG中embedding的两个新进展BGE-M3及MRL：兼看几个有趣的综述及水印工作https://mp.weixin.qq.com/s/NJNnyfNaeVNjO1GnJ46T1g</p><p>[5] 微软放大招：基于RAG与Fine-Tuning的数据整合策略探索https://mp.weixin.qq.com/s/oeQnMGmGMT0R8x3h35weqg</p><h3 id="42-优化知识密集型问答任务"><span class="mr-2">4.2 优化知识密集型问答任务</span><a href="#42-优化知识密集型问答任务" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>每个句子触发1次检索，用前1个句子作为$q$，$q_{t-1}$和$R(q_{t-1})$生成$y_t$。</p><h4 id="-realm"><span class="mr-2">① REALM</span><a href="#-realm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240305170324686.png" alt="image-20240305170324686" data-proofer-ignore></p><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240305170351995.png" alt="image-20240305170351995" data-proofer-ignore></p><h4 id="-ircot"><span class="mr-2">② IRCoT</span><a href="#-ircot" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240222114316898.png" alt="image-20240222114316898" data-proofer-ignore></p><p>[1] 「think step by step」还不够，让模型「think more steps」更有用https://mp.weixin.qq.com/s/UgglOk-u6Qv3IrY6aWcarQ</p><p>[2] In-Context Learning玩法大全https://mp.weixin.qq.com/s/NLWCuzcCdwljQfzu-Jd9lQ</p><blockquote><p>问题分解方法是手动注释特定任务的示例，以指导LMs在生成输出的同时生成分解的子问题。</p></blockquote><h4 id="-self-ask"><span class="mr-2">③ Self-Ask</span><a href="#-self-ask" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240226094246377.png" alt="image-20240226094246377" data-proofer-ignore></p><p>实验结果：</p><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240226095943473.png" alt="image-20240226095943473" data-proofer-ignore></p><p>GPT3：Davinci-002</p><p>上表显示了Bamb&amp;2wikimultihop&amp;musique三个数据集的<strong>Accuracy</strong>指标，Bamb是作者人工判断的，剩下两个是“完全匹配”。</p><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240226095951622.png" alt="image-20240226095951622" data-proofer-ignore></p><p>上表显示了和Least-to-Most模型的对比，toks指生成的回答的长度。</p><h4 id="-least-to-most"><span class="mr-2">④ Least-to-Most</span><a href="#-least-to-most" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240226105257973.png" alt="image-20240226105257973" data-proofer-ignore></p><p>第一阶段：先“问”模型回答问题首先需要知道什么</p><p>第二阶段：引导模型先生成子问题的回答，然后将子问题及其回答作为instruction补充在input中，引导模型生成最后的回答</p><p>[1] 如何使用快速压缩将RAG的Prompt成本削减80%https://mp.weixin.qq.com/s/7j1eTqD3DnRH-o2ZjREuPg</p><h4 id="-flare"><span class="mr-2">⑤ FLARE</span><a href="#-flare" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240305170722600.png" alt="image-20240305170722600" data-proofer-ignore></p><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240305170738406.png" alt="image-20240305170738406" data-proofer-ignore></p><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240305170751957.png" alt="image-20240305170751957" data-proofer-ignore></p><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240305170817216.png" alt="image-20240305170817216" data-proofer-ignore></p><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240305170558551.png" alt="image-20240305170558551" data-proofer-ignore></p><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240305170635693.png" alt="image-20240305170635693" data-proofer-ignore></p><p>[1] Active RAG – FLARE 详解https://mp.weixin.qq.com/s/YTxOjwjNvyhrUtVtmQ-rRQ</p><p>[2] logprobs-OpenAI fine tune数据集准备最佳实践https://mp.weixin.qq.com/s/S9t7gw55MIaCGY60iaso7Q</p><h4 id="-self-rag"><span class="mr-2">⑤ Self-RAG</span><a href="#-self-rag" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>[1] 也看引入自我反思的大模型RAG检索增强生成框架：SELF-RAG的数据构造及基本实现思路https://mp.weixin.qq.com/s/VyrkSnYb4Uss8cfZp1yrvA</p><h3 id="44-rag的评估方法"><span class="mr-2">4.4 RAG的评估方法</span><a href="#44-rag的评估方法" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><h4 id="a评估方式"><span class="mr-2">A.评估方式</span><a href="#a评估方式" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240229110911368.png" alt="image-20240229110911368" data-proofer-ignore></p><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240229110929658.png" alt="image-20240229110929658" data-proofer-ignore></p><p><strong>① NDCG</strong>（Normalized Discounted Cumulative Gain，归一化折损累计增益）是一种用于评估排序结果的指标。在搜索和推荐任务中，系统常常返回一个项目列表。NDCG的目的是衡量这个返回的列表的质量。原理如下：</p><ol><li><strong>Gain（增益）</strong>：表示一个列表中所有项目的相关性分数。<code class="language-plaintext highlighter-rouge">rel(i)</code> 表示第 <code class="language-plaintext highlighter-rouge">i</code> 个项目的相关性得分。<li><strong>Cumulative Gain（累积增益）</strong>：对前 <code class="language-plaintext highlighter-rouge">k</code> 个项目的 Gain 进行累加。$CG_k = \sum_{i=1}^{k} rel(i)$<li><strong>Discounted Cumulative Gain（折损累计增益）</strong>：考虑了排序顺序的因素，使得排名靠前的项目增益更高，对排名靠后的项目进行折损。DCG 的计算公式为：$DCG_k = \sum_{i=1}^{k} \frac{rel(i)}{\log_2(i+1)}$。其中，<code class="language-plaintext highlighter-rouge">i</code> 表示项目的排名，<code class="language-plaintext highlighter-rouge">rel(i)</code> 是项目的相关性得分。<li><strong>Ideal DCG（理想的 DCG）</strong>：根据相关性降序排列的最佳状态，即排列到最好的状态。IDCG 是 DCG 的理想值，它是一个参考点。<li><strong>Normalized DCG（归一化折损累计增益）</strong>：用 DCG 除以 IDCG 来表示，这样可以将 DCG 归一化到 [0, 1] 范围内。NDCG 的计算公式为：$NDCG = \frac{DCG}{IDCG}$。</ol><p>通过 NDCG，我们可以在不受不同查询结果数量的影响的前提下相对地评估不同查询或推荐结果的质量。</p><p>② <strong>MRR</strong>，该指标越大越好（即预测排名越靠前，倒数就越大，求和结果越大越好）</p><div class="table-wrapper"><table><tbody><tr><td>$\text{MRR} = \frac{1}{Q} \sum_{i=1}^{<td>Q<td>} \frac{1}{\text{rank}_i}$</table></div><p>RAG 的评估方法多样，主要包括三个质量评分：<strong>上下文相关性、答案忠实性和答案相关性</strong>。此外，评估还涉及四个关键能力：噪声鲁棒性、拒答能力、信息整合和反事实鲁棒性。这些评估维度结合了传统量化指标和针对 RAG 特性的专门评估标准，尽管这些标准尚未统一。</p><ul><li>忠实度：衡量生成的答案与给定上下文的事实一致性。</ul><p>$\text{忠实度} = \frac{\text{句子中的基本事实可以从上下文中推断出的句子数量}}{\text{生成回答的句子总数}}$</p><ul><li>答案相关性：评估生成的答案与用户问题之间的相关程度。</ul><p>​ 思想：如果生成的答案准确地解决了最初的问题，LLM应该能够从答案中生成与原始问题相符的问题。</p><p>​ 做法：为了计算这个分数，LLM会被提示多次为生成的答案生成适当的问题，并测量这些生成的问题与原始问题之间的平均余弦相似度。</p><p>$score_{AR} = \frac{\sum_{i=0}^{k-1} \text{cos_sim} (Q, q’_{i})}{k} $</p><p>$q’=LLM(answer)$</p><p>$Answer Relevance = \sum_{i=0}^{k-1} \text{cos_sim} (Question, LLM(answer)_{i})$</p><ul><li><p>上下文相关性：评估检索到的上下文的相关性。</p><p>准确率：检索到的context中与query相关的句子数量/检索到的context的句子总数</p></ul><div class="table-wrapper"><table><tbody><tr><td>​ 理想情况下，检索到的Context应只包含解答question的信息。 我们首先通过识别检索到的Context中与回答question相关的句子数量来估计<td>S<td>的值。 最终分数由以下公式确定：</table></div><p>$\text{上下文相关性} = \frac{\text{检索到的上下文中与真实答案相关的句子数量}}{\text{真实答案中的句子总数}}$</p><p>在评估框架方面，存在如 RGB 和 RECALL 这样的基准测试，以及 RAGAS、ARES 和 TruLens 等自动化评估工具，它们有助于全面衡量 RAG 模型的表现。表中汇总了如何将传统量化指标应用于 RAG 评估以及各种 RAG 评估框架的评估内容，包括评估的对象、维度和指标，为深入理解 RAG 模型的性能和潜在应用提供了宝贵信息。</p><p>$score_{EM}$</p><p><img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJgGjh6IllvTWYL5bONOuQLP1tnWJhx6mNGLuMlZ7AZXrh8cSTibZBsBTlfV197cMX0jniboVAuWyw/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" data-proofer-ignore></p><p><img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJgGjh6IllvTWYL5bONOuQc7zq93SEQC9uibGiaicLiboX5Iibvtn2R7PWPuxudnkZEUpXMjsA9qeqVIw/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片" data-proofer-ignore></p><p><img data-src="../../../../assets/img/2024-02-21-RAG检索知识增强/image-20240306155607361.png" alt="image-20240306155607361" data-proofer-ignore></p><p>搜索推荐评价指标Precision@k、Recall@k、F1@k、NDCG@k_precision@5-CSDN博客https://blog.csdn.net/guolindonggld/article/details/121114309</p><p>NDCG 归一化折损累计增益的动机、讲解、公式、实现 - 知乎https://zhuanlan.zhihu.com/p/474423793</p><div class="table-wrapper"><table><tbody><tr><td>Advanced RAG Techniques: an Illustrated Overview<td>by IVAN ILIN<td>Towards AIhttps://pub.towardsai.net/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6</table></div><p>【RAG系列探索之旅·第十弹】RAG评估全攻略：方法、指标与框架https://mp.weixin.qq.com/s/EJteC2assR-mGoEv-n5Q_w</p><p>05细说RAG评估指标https://mp.weixin.qq.com/s/jVs2S4O8Sd_AtzEWdFRjoQ</p><p>再看大模型RAG检索增强如何评估：RAGAS开源自动化评估框架https://mp.weixin.qq.com/s/TrXWXkQIYTVsS1o4IZjs9w</p><p>大模型RAG检索增强问答如何评估：噪声、拒答、反事实、信息整合四大能力评测任务探索https://mp.weixin.qq.com/s/YFji1s2yT8MTrO3z9_aI_w</p><p>如何评估 RAG 应用的质量？最典型的方法论和评估工具都在这里了https://mp.weixin.qq.com/s/OnfSxBJx_lVYV_MtyViUMw</p><div class="table-wrapper"><table><tbody><tr><td>LLM之RAG实战（二十七）<td>如何评估RAG系统https://mp.weixin.qq.com/s/4EcYxBpPLMrbACy3aSyOyQ</table></div><p>科普贴：一文说透RAG的方方面面https://mp.weixin.qq.com/s/mrnU3DLbGsumJ7mOjosh8g RAG 评估框架 – RAGAShttps://mp.weixin.qq.com/s/MPUPbyjuIVhw1wM3l0P1aA NDCG - 知乎https://zhuanlan.zhihu.com/p/371432647</p><p>高级RAG(四)：Ragas评估 - - 派神 -的文章 - 知乎https://zhuanlan.zhihu.com/p/675777378</p><p>学习检索增强生成(RAG)技术，看这篇就够了——热门RAG文章摘译(9篇) - 吕阿华的文章 - 知乎https://zhuanlan.zhihu.com/p/673392898</p><div class="table-wrapper"><table><tbody><tr><td>🚀 Get Started<td>Ragashttps://docs.ragas.io/en/latest/getstarted/index.html</table></div><p>RAG 评估框架 – ARES - 知乎https://zhuanlan.zhihu.com/p/677767672</p><div class="table-wrapper"><table><tbody><tr><td>Evaluating Naive RAG and Advanced RAG pipeline using langchain v.0.1.0 and RAGAS<td>by Plaban Nayak<td>Feb, 2024<td>AI Planethttps://medium.aiplanet.com/evaluating-naive-rag-and-advanced-rag-pipeline-using-langchain-v-0-1-0-and-ragas-17d24e74e5cf</table></div><p>openai-cookbook/examples/evaluation/Evaluate_RAG_with_LlamaIndex.ipynb at main · openai/openai-cookbookhttps://github.com/openai/openai-cookbook/blob/main/examples/evaluation/Evaluate_RAG_with_LlamaIndex.ipynb</p><p>也看大模型的选择题评估方式是否鲁棒：兼看RAG知识增强问答中的知识冲突和评测基准https://mp.weixin.qq.com/s/LYJcqvWsqnTkQcFnPd2WKg</p><p>https://arxiv.org/pdf/2309.15217.pdf</p><h2 id="rag的未来展望"><span class="mr-2">RAG的未来展望</span><a href="#rag的未来展望" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><div class="table-wrapper"><table><tbody><tr><td>Gemini 1.5 Pro<td>快速工程指南https://www.promptingguide.ai/models/gemini-pro</table></div><p>谷歌10M上下文窗口正在杀死RAG？被Sora夺走风头的Gemini被低估了？https://mp.weixin.qq.com/s/t3fsKksf7DWwVJY5vldPNw</p><p>LLM长上下文时代，RAG的机遇与挑战https://mp.weixin.qq.com/s/LhwWE6t_muigcLbXAAKQ_w</p><p>负拒绝问题：</p><p>首先，什么问题需要LLM拒绝回答？1. 本身不具备的知识拒绝回答，2. 上下文中提供的信息仍然不包含回答问题必要的信息时拒绝回答，3. 上下文中提供的信息包含反事实错误时识别出来并拒绝回答。</p><p>针对第一种问题可以采用置信度的策略，针对模型的直接回答中提取置信度低的token的个数，当数量超过总token的30%（此阈值可调参）视为LLM无法回答问题，给出拒绝回答。</p><ul><li><a href="https://www.zhihu.com/question/600531471">使用拒绝采样（Rejection Sampling）技术，让LLM在生成答案之后，对答案进行评估，如果评估得分低于某个阈值，就拒绝输出该答案，或者重新生成一个新的答案</a><a href="https://www.zhihu.com/question/600531471">4</a><a href="https://zhuanlan.zhihu.com/p/683702878">5</a>。<li><a href="https://zhuanlan.zhihu.com/p/676939361">使用自我评估（Self-Evaluation）技术，让LLM在生成答案之后，对答案进行自我检查，如果发现答案与问题不匹配，或者包含错误或不确定的信息，就拒绝输出该答案，或者给出一个带有免责声明的答案</a><a href="https://zhuanlan.zhihu.com/p/676939361">6</a><a href="https://zhuanlan.zhihu.com/p/666278645">7</a></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/nlp/'>NLP</a>, <a href='/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/'>基础知识</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/nlp/" class="post-tag no-text-decoration" >nlp</a> <a href="/tags/rag/" class="post-tag no-text-decoration" >RAG</a> <a href="/tags/%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/" class="post-tag no-text-decoration" >技术综述</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> 本文由作者按照 <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> 进行授权</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">分享</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=RAG+-+zoe+Chen&url=https%3A%2F%2Fzoechen119.github.io%2Fposts%2FRAG%25E6%25A3%2580%25E7%25B4%25A2%25E7%259F%25A5%25E8%25AF%2586%25E5%25A2%259E%25E5%25BC%25BA%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=RAG+-+zoe+Chen&u=https%3A%2F%2Fzoechen119.github.io%2Fposts%2FRAG%25E6%25A3%2580%25E7%25B4%25A2%25E7%259F%25A5%25E8%25AF%2586%25E5%25A2%259E%25E5%25BC%25BA%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fzoechen119.github.io%2Fposts%2FRAG%25E6%25A3%2580%25E7%25B4%25A2%25E7%259F%25A5%25E8%25AF%2586%25E5%25A2%259E%25E5%25BC%25BA%2F&text=RAG+-+zoe+Chen" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="分享链接" data-title-succeed="链接已复制！"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">最近更新</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/C25_11%E5%85%A5%E9%97%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%860/">【NLP入门趣味题】肉眼找朋友</a><li><a href="/posts/C25_11%E5%85%A5%E9%97%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%861/">【NLP入门趣味题】探索语言模型与词向量</a><li><a href="/posts/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/">强化学习</a><li><a href="/posts/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AE%9E%E9%AA%8C/">多模态实验</a><li><a href="/posts/%E5%A4%9A%E6%A8%A1%E6%80%81RAG/">多模态rag</a></ul></div><div id="access-tags"><div class="panel-heading">热门标签</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/nlp/">nlp</a> <a class="post-tag" href="/tags/%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/">技术综述</a> <a class="post-tag" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a> <a class="post-tag" href="/tags/rag/">RAG</a> <a class="post-tag" href="/tags/%E8%AF%AD%E8%A8%80%E5%AD%A6/">语言学</a> <a class="post-tag" href="/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/">预训练模型</a> <a class="post-tag" href="/tags/bert/">BERT</a> <a class="post-tag" href="/tags/courses/">Courses</a> <a class="post-tag" href="/tags/chatgpt/">ChatGPT</a> <a class="post-tag" href="/tags/mamba/">Mamba</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">文章内容</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>相关文章</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/RAG/"><div class="card-body"> <em class="small" data-ts="1709136000" data-df="YYYY-MM-DD" > 2024-02-29 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>RAG</h3><div class="text-muted small"><p> RAG调研 一、一些共识 External knowledge is the key to resolving the problems of LLMs such as hallucination and outdated knowledge, which can make LLMs generate more accurate and reliable responses thr...</p></div></div></a></div><div class="card"> <a href="/posts/RAG%E6%A3%80%E7%B4%A2%E7%9F%A5%E8%AF%86%E5%A2%9E%E5%BC%BA-(2)/"><div class="card-body"> <em class="small" data-ts="1701619200" data-df="YYYY-MM-DD" > 2023-12-04 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>RAG</h3><div class="text-muted small"><p> RAG调研 一、一些共识 External knowledge is the key to resolving the problems of LLMs such as hallucination and outdated knowledge, which can make LLMs generate more accurate and reliable responses thr...</p></div></div></a></div><div class="card"> <a href="/posts/%E7%9F%A5%E8%AF%86%E5%A2%9E%E5%BC%BA%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93/"><div class="card-body"> <em class="small" data-ts="1678809600" data-df="YYYY-MM-DD" > 2023-03-15 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>知识增强技术总结</h3><div class="text-muted small"><p> 知识增强的价值关键 预训练语言模型目前的瓶颈： 不可解释，黑盒模型 下游任务需要大量标注数据 虽然少样本中人工给出思维链提示的成本很小，但这种注释成本相对于微调还是令人望而却步（也可以用synthetic data generation合成数据生成, or zero-shot generalization零样本泛化来处理这个问题）。 推理能力差 ChatGPT和之前PLM的...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/PaperNote_LLM%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7%E7%BB%BC%E8%BF%B0/" class="btn btn-outline-primary" prompt="上一篇"><p>Papernote_llm可解释性综述</p></a> <a href="/posts/RAG/" class="btn btn-outline-primary" prompt="下一篇"><p>RAG</p></a></div><script src="https://utteranc.es/client.js" repo="zoeChen119/zoeChen119.github.io" issue-term="title" crossorigin="anonymous" async> </script> <script type="text/javascript"> $(function() { const origin = "https://utteranc.es"; const iframe = "iframe.utterances-frame"; const lightTheme = "github-light"; const darkTheme = "github-dark"; let initTheme = lightTheme; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches)) { initTheme = darkTheme; } addEventListener("message", (event) => { let theme; /* credit to <https://github.com/utterance/utterances/issues/170#issuecomment-594036347> */ if (event.origin === origin) { /* page initial */ theme = initTheme; } else if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { /* global theme mode changed */ const mode = event.data.message; theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme); } else { return; } const message = { type: "set-theme", theme: theme }; const utterances = document.querySelector(iframe).contentWindow; utterances.postMessage(message, origin); }); }); </script></div></div><footer class="row pl-3 pr-3"><div class="col-12 d-flex justify-content-between align-items-center text-muted pl-0 pr-0"><div class="footer-left"><p class="mb-0"> © 2025 <a href="https://github.com/zoeChen119">陈政伊</a>. <span data-toggle="tooltip" data-placement="top" title="除非另有说明，本网站上的博客文章均由作者按照知识共享署名 4.0 国际 (CC BY 4.0) 许可协议进行授权。">保留部分权利。</span></p></div><div class="footer-right"><p class="mb-0"> 本站由 <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> 生成，采用 <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> 主题。</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">热门标签</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/nlp/">nlp</a> <a class="post-tag" href="/tags/%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/">技术综述</a> <a class="post-tag" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a> <a class="post-tag" href="/tags/rag/">RAG</a> <a class="post-tag" href="/tags/%E8%AF%AD%E8%A8%80%E5%AD%A6/">语言学</a> <a class="post-tag" href="/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/">预训练模型</a> <a class="post-tag" href="/tags/bert/">BERT</a> <a class="post-tag" href="/tags/courses/">Courses</a> <a class="post-tag" href="/tags/chatgpt/">ChatGPT</a> <a class="post-tag" href="/tags/mamba/">Mamba</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">发现新版本的内容。</p><button type="button" class="btn btn-primary" aria-label="Update"> 更新 </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">搜索结果为空</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/zh.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
