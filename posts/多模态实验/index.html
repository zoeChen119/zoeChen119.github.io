<!DOCTYPE html><html lang="zh-CN" data-mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="多模态实验" /><meta property="og:locale" content="zh_CN" /><meta name="description" content="多模态实验过程记录" /><meta property="og:description" content="多模态实验过程记录" /><link rel="canonical" href="https://zoechen119.github.io/posts/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AE%9E%E9%AA%8C/" /><meta property="og:url" content="https://zoechen119.github.io/posts/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AE%9E%E9%AA%8C/" /><meta property="og:site_name" content="zoe Chen" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2025-02-11T00:00:00+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="多模态实验" /><meta name="twitter:site" content="@twitter_username" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-04-10T17:09:41+08:00","datePublished":"2025-02-11T00:00:00+08:00","description":"多模态实验过程记录","headline":"多模态实验","mainEntityOfPage":{"@type":"WebPage","@id":"https://zoechen119.github.io/posts/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AE%9E%E9%AA%8C/"},"url":"https://zoechen119.github.io/posts/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AE%9E%E9%AA%8C/"}</script><title>多模态实验 | zoe Chen</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="zoe Chen"><meta name="application-name" content="zoe Chen"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="/assets/img/avatar.jfif" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">zoe Chen</a></div><div class="site-subtitle font-italic">nlper, dler, sims4er</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>首页</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>分类</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>标签</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>归档</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>关于</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/zoeChen119" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['zoe9698','163.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> 首页 </a> </span> <span>多模态实验</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> 文章</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="搜索..."> </span> <span id="search-cancel" >取消</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>多模态实验</h1><div class="post-meta text-muted"> <span> 发表于 <em class="" data-ts="1739203200" data-df="YYYY-MM-DD" data-toggle="tooltip" data-placement="bottom"> 2025-02-11 </em> </span> <span> 更新于 <em class="" data-ts="1744276181" data-df="YYYY-MM-DD" data-toggle="tooltip" data-placement="bottom"> 2025-04-10 </em> </span><div class="d-flex justify-content-between"> <span> 作者 <em> <a href="https://github.com/zoeChen119">陈政伊</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3099 字"> <em>17 分钟</em>阅读</span></div></div></div><div class="post-content"><h1 id="多模态实验过程记录">多模态实验过程记录</h1><h2 id="实验1colpaligemma-3b-pt-448-base测试"><span class="mr-2">实验1：colpaligemma-3b-pt-448-base测试</span><a href="#实验1colpaligemma-3b-pt-448-base测试" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><img data-src="./../../../assets/img/2025-2-11-多模态实验/image-20250211185813569.png" alt="image-20250211185813569" data-proofer-ignore></p><div class="language-json highlighter-rouge"><div class="code-header"> <span data-label-text="JSON"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
</pre><td class="rouge-code"><pre><span class="err">PaliGemmaForConditionalGeneration(</span><span class="w">
  </span><span class="err">(vision_tower):</span><span class="w"> </span><span class="err">SiglipVisionModel(</span><span class="w">
    </span><span class="err">(vision_model):</span><span class="w"> </span><span class="err">SiglipVisionTransformer(</span><span class="w">
      </span><span class="err">(embeddings):</span><span class="w"> </span><span class="err">SiglipVisionEmbeddings(</span><span class="w">
        </span><span class="err">(patch_embedding):</span><span class="w"> </span><span class="err">Conv</span><span class="mi">2</span><span class="err">d(</span><span class="mi">3</span><span class="err">,</span><span class="w"> </span><span class="mi">1152</span><span class="err">,</span><span class="w"> </span><span class="err">kernel_size=(</span><span class="mi">14</span><span class="err">,</span><span class="w"> </span><span class="mi">14</span><span class="err">),</span><span class="w"> </span><span class="err">stride=(</span><span class="mi">14</span><span class="err">,</span><span class="w"> </span><span class="mi">14</span><span class="err">),</span><span class="w"> </span><span class="err">padding=valid)</span><span class="w">
        </span><span class="err">(position_embedding):</span><span class="w"> </span><span class="err">Embedding(</span><span class="mi">1024</span><span class="err">,</span><span class="w"> </span><span class="mi">1152</span><span class="err">)</span><span class="w">
      </span><span class="err">)</span><span class="w">
      </span><span class="err">(encoder):</span><span class="w"> </span><span class="err">SiglipEncoder(</span><span class="w">
        </span><span class="err">(layers):</span><span class="w"> </span><span class="err">ModuleList(</span><span class="w">
          </span><span class="err">(</span><span class="mi">0-26</span><span class="err">):</span><span class="w"> </span><span class="mi">27</span><span class="w"> </span><span class="err">x</span><span class="w"> </span><span class="err">SiglipEncoderLayer(</span><span class="w">
            </span><span class="err">(self_attn):</span><span class="w"> </span><span class="err">SiglipSdpaAttention(</span><span class="w">
              </span><span class="err">(k_proj):</span><span class="w"> </span><span class="err">Linear(in_features=</span><span class="mi">1152</span><span class="err">,</span><span class="w"> </span><span class="err">out_features=</span><span class="mi">1152</span><span class="err">,</span><span class="w"> </span><span class="err">bias=True)</span><span class="w">
              </span><span class="err">(v_proj):</span><span class="w"> </span><span class="err">Linear(in_features=</span><span class="mi">1152</span><span class="err">,</span><span class="w"> </span><span class="err">out_features=</span><span class="mi">1152</span><span class="err">,</span><span class="w"> </span><span class="err">bias=True)</span><span class="w">
              </span><span class="err">(q_proj):</span><span class="w"> </span><span class="err">Linear(in_features=</span><span class="mi">1152</span><span class="err">,</span><span class="w"> </span><span class="err">out_features=</span><span class="mi">1152</span><span class="err">,</span><span class="w"> </span><span class="err">bias=True)</span><span class="w">
              </span><span class="err">(out_proj):</span><span class="w"> </span><span class="err">Linear(in_features=</span><span class="mi">1152</span><span class="err">,</span><span class="w"> </span><span class="err">out_features=</span><span class="mi">1152</span><span class="err">,</span><span class="w"> </span><span class="err">bias=True)</span><span class="w">
            </span><span class="err">)</span><span class="w">
            </span><span class="err">(layer_norm</span><span class="mi">1</span><span class="err">):</span><span class="w"> </span><span class="err">LayerNorm((</span><span class="mi">1152</span><span class="err">,),</span><span class="w"> </span><span class="err">eps=</span><span class="mi">1e-06</span><span class="err">,</span><span class="w"> </span><span class="err">elementwise_affine=True)</span><span class="w">
            </span><span class="err">(mlp):</span><span class="w"> </span><span class="err">SiglipMLP(</span><span class="w">
              </span><span class="err">(activation_fn):</span><span class="w"> </span><span class="err">PytorchGELUTanh()</span><span class="w">
              </span><span class="err">(fc</span><span class="mi">1</span><span class="err">):</span><span class="w"> </span><span class="err">Linear(in_features=</span><span class="mi">1152</span><span class="err">,</span><span class="w"> </span><span class="err">out_features=</span><span class="mi">4304</span><span class="err">,</span><span class="w"> </span><span class="err">bias=True)</span><span class="w">
              </span><span class="err">(fc</span><span class="mi">2</span><span class="err">):</span><span class="w"> </span><span class="err">Linear(in_features=</span><span class="mi">4304</span><span class="err">,</span><span class="w"> </span><span class="err">out_features=</span><span class="mi">1152</span><span class="err">,</span><span class="w"> </span><span class="err">bias=True)</span><span class="w">
            </span><span class="err">)</span><span class="w">
            </span><span class="err">(layer_norm</span><span class="mi">2</span><span class="err">):</span><span class="w"> </span><span class="err">LayerNorm((</span><span class="mi">1152</span><span class="err">,),</span><span class="w"> </span><span class="err">eps=</span><span class="mi">1e-06</span><span class="err">,</span><span class="w"> </span><span class="err">elementwise_affine=True)</span><span class="w">
          </span><span class="err">)</span><span class="w">
        </span><span class="err">)</span><span class="w">
      </span><span class="err">)</span><span class="w">
      </span><span class="err">(post_layernorm):</span><span class="w"> </span><span class="err">LayerNorm((</span><span class="mi">1152</span><span class="err">,),</span><span class="w"> </span><span class="err">eps=</span><span class="mi">1e-06</span><span class="err">,</span><span class="w"> </span><span class="err">elementwise_affine=True)</span><span class="w">
    </span><span class="err">)</span><span class="w">
  </span><span class="err">)</span><span class="w">
  </span><span class="err">(multi_modal_projector):</span><span class="w"> </span><span class="err">PaliGemmaMultiModalProjector(</span><span class="w">
    </span><span class="err">(linear):</span><span class="w"> </span><span class="err">Linear(in_features=</span><span class="mi">1152</span><span class="err">,</span><span class="w"> </span><span class="err">out_features=</span><span class="mi">2048</span><span class="err">,</span><span class="w"> </span><span class="err">bias=True)</span><span class="w">
  </span><span class="err">)</span><span class="w">
  </span><span class="err">(language_model):</span><span class="w"> </span><span class="err">GemmaForCausalLM(</span><span class="w">
    </span><span class="err">(model):</span><span class="w"> </span><span class="err">GemmaModel(</span><span class="w">
      </span><span class="err">(embed_tokens):</span><span class="w"> </span><span class="err">Embedding(</span><span class="mi">257216</span><span class="err">,</span><span class="w"> </span><span class="mi">2048</span><span class="err">,</span><span class="w"> </span><span class="err">padding_idx=</span><span class="mi">0</span><span class="err">)</span><span class="w">
      </span><span class="err">(layers):</span><span class="w"> </span><span class="err">ModuleList(</span><span class="w">
        </span><span class="err">(</span><span class="mi">0-17</span><span class="err">):</span><span class="w"> </span><span class="mi">18</span><span class="w"> </span><span class="err">x</span><span class="w"> </span><span class="err">GemmaDecoderLayer(</span><span class="w">
          </span><span class="err">(self_attn):</span><span class="w"> </span><span class="err">GemmaAttention(</span><span class="w">
            </span><span class="err">(q_proj):</span><span class="w"> </span><span class="err">Linear(in_features=</span><span class="mi">2048</span><span class="err">,</span><span class="w"> </span><span class="err">out_features=</span><span class="mi">2048</span><span class="err">,</span><span class="w"> </span><span class="err">bias=False)</span><span class="w">
            </span><span class="err">(k_proj):</span><span class="w"> </span><span class="err">Linear(in_features=</span><span class="mi">2048</span><span class="err">,</span><span class="w"> </span><span class="err">out_features=</span><span class="mi">256</span><span class="err">,</span><span class="w"> </span><span class="err">bias=False)</span><span class="w">
            </span><span class="err">(v_proj):</span><span class="w"> </span><span class="err">Linear(in_features=</span><span class="mi">2048</span><span class="err">,</span><span class="w"> </span><span class="err">out_features=</span><span class="mi">256</span><span class="err">,</span><span class="w"> </span><span class="err">bias=False)</span><span class="w">
            </span><span class="err">(o_proj):</span><span class="w"> </span><span class="err">Linear(in_features=</span><span class="mi">2048</span><span class="err">,</span><span class="w"> </span><span class="err">out_features=</span><span class="mi">2048</span><span class="err">,</span><span class="w"> </span><span class="err">bias=False)</span><span class="w">
          </span><span class="err">)</span><span class="w">
          </span><span class="err">(mlp):</span><span class="w"> </span><span class="err">GemmaMLP(</span><span class="w">
            </span><span class="err">(gate_proj):</span><span class="w"> </span><span class="err">Linear(in_features=</span><span class="mi">2048</span><span class="err">,</span><span class="w"> </span><span class="err">out_features=</span><span class="mi">16384</span><span class="err">,</span><span class="w"> </span><span class="err">bias=False)</span><span class="w">
            </span><span class="err">(up_proj):</span><span class="w"> </span><span class="err">Linear(in_features=</span><span class="mi">2048</span><span class="err">,</span><span class="w"> </span><span class="err">out_features=</span><span class="mi">16384</span><span class="err">,</span><span class="w"> </span><span class="err">bias=False)</span><span class="w">
            </span><span class="err">(down_proj):</span><span class="w"> </span><span class="err">Linear(in_features=</span><span class="mi">16384</span><span class="err">,</span><span class="w"> </span><span class="err">out_features=</span><span class="mi">2048</span><span class="err">,</span><span class="w"> </span><span class="err">bias=False)</span><span class="w">
            </span><span class="err">(act_fn):</span><span class="w"> </span><span class="err">PytorchGELUTanh()</span><span class="w">
          </span><span class="err">)</span><span class="w">
          </span><span class="err">(input_layernorm):</span><span class="w"> </span><span class="err">GemmaRMSNorm((</span><span class="mi">2048</span><span class="err">,),</span><span class="w"> </span><span class="err">eps=</span><span class="mi">1e-06</span><span class="err">)</span><span class="w">
          </span><span class="err">(post_attention_layernorm):</span><span class="w"> </span><span class="err">GemmaRMSNorm((</span><span class="mi">2048</span><span class="err">,),</span><span class="w"> </span><span class="err">eps=</span><span class="mi">1e-06</span><span class="err">)</span><span class="w">
        </span><span class="err">)</span><span class="w">
      </span><span class="err">)</span><span class="w">
      </span><span class="err">(norm):</span><span class="w"> </span><span class="err">GemmaRMSNorm((</span><span class="mi">2048</span><span class="err">,),</span><span class="w"> </span><span class="err">eps=</span><span class="mi">1e-06</span><span class="err">)</span><span class="w">
      </span><span class="err">(rotary_emb):</span><span class="w"> </span><span class="err">GemmaRotaryEmbedding()</span><span class="w">
    </span><span class="err">)</span><span class="w">
    </span><span class="err">(lm_head):</span><span class="w"> </span><span class="err">Linear(in_features=</span><span class="mi">2048</span><span class="err">,</span><span class="w"> </span><span class="err">out_features=</span><span class="mi">257216</span><span class="err">,</span><span class="w"> </span><span class="err">bias=False)</span><span class="w">
  </span><span class="err">)</span><span class="w">
</span><span class="err">)</span><span class="w">
</span></pre></table></code></div></div><p><strong>图中左侧的Vision LLM</strong>：PaliGemma-3B 是一种视觉-语言模型（VLM），该模型使用的ViTs模型是SigLIP-So400m/14，它可以生成高质量的图像嵌入。</p><p><strong>1》</strong>processor = <strong>AutoProcessor</strong>.from_pretrained(model_name)</p><p>inputs = processor(images=image, text=prompt, return_tensors=”pt”)</p><blockquote><p>inputs[‘input_ids’].shape = torch.Size([1, 1034])</p><p>inputs[‘attention_mask’].shape = torch.Size([1, 1034])</p><p>inputs[‘pixel_values’].shape = torch.Size([1, 3, 448, 448])</p></blockquote><p><strong>2》</strong>batch_images = <strong>ColPaliProcessor</strong>.process_images(RGB图像列表)</p><blockquote><p>batch_images = processor.process_images(images).to(model.device)</p><p>batch_queries = processor.process_queries(queries).to(model.device)</p><p>batch_images [‘input_ids’].shape = torch.Size([2, 1030])</p><p>batch_images [‘attention_mask’].shape = torch.Size([1, 1030])</p><p>batch_images [‘pixel_values’].shape = torch.Size([2, 3, 448, 448])</p><p>batch_queries[‘input_ids’].shape = torch.Size([2, 27])</p><p>batch_queries[‘attention_mask’].shape = torch.Size([2, 27])</p></blockquote><p>image_embeddings = model(**batch_images) # with torch.no_grad():</p><p><img data-src="./../../../assets/img/2025-2-11-多模态实验/image-20250211191729015.png" alt="image-20250211191729015" data-proofer-ignore></p><p>proj就是一层用于降维的线性层。</p><p><strong>图中右侧的LLM：</strong>该模型使用的LLMs模型是Gemma-2B。一个特别有趣的特性是，PaliGemma-3B 的文本模型是通过带有前缀（指令文本和图像标记）的全块注意力机制进行微调的。</p><p>batch_queries = <strong>ColPaliProcessor</strong>.process_queries(文本句子列表)</p><p>query_embeddings = model(**batch_queries) # with torch.no_grad():</p><p><strong>应用：</strong></p><p>scores = <strong>ColPaliProcessor</strong>.score_multi_vector(query_embeddings, image_embeddings)</p><h2 id="base模型选择"><span class="mr-2">Base模型选择</span><a href="#base模型选择" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="1"><span class="mr-2">（1）</span><a href="#1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><strong>Metric-AI/ColQwen2.5-3b-multilingual-v1.0</strong></p><ol><li><p>Vidore榜单排名第2</p><p><img data-src="../../../assets/img/2025-2-11-多模态实验/image-20250310090129656.png" alt="image-20250310090129656" data-proofer-ignore></p><li><p>是lora微调后的模型</p></ol><blockquote><p>是否能把lora微调后的和没有lora微调的模型放在一起对比？</p></blockquote><ol><li>这是一个多语言模型</ol><p><strong>Alibaba-NLP/gme-Qwen2-VL-2B-Instruct</strong></p><ol><li>Vidore榜单排名第13</ol><p><img data-src="../../../assets/img/2025-2-11-多模态实验/image-20250310090934976.png" alt="image-20250310090934976" data-proofer-ignore></p><ol><li>原模型</ol><blockquote><p>排名靠前的都是lora微调后的模型，就这一个阿里的不是</p></blockquote><h3 id="2论文1多模态综述"><span class="mr-2">（2）论文1：多模态综述</span><a href="#2论文1多模态综述" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>2025年2月的</p><p><img data-src="../../../assets/img/2025-2-11-多模态实验/image-20250310092332565.png" alt="image-20250310092332565" data-proofer-ignore></p><h4 id="44-generation-techniques"><span class="mr-2">4.4 Generation Techniques</span><a href="#44-generation-techniques" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><img data-src="../../../assets/img/2025-2-11-多模态实验/image-20250310103855124.png" alt="image-20250310103855124" data-proofer-ignore></p><h4 id="63-agent-based-and-self-guided-systems"><span class="mr-2">6.3 Agent-Based and Self-Guided Systems</span><a href="#63-agent-based-and-self-guided-systems" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>将强化学习和端到端与人一致的反馈结合到多模态rag中，在很大程度上仍未被探索，但在增强这些系统方面具有巨大的潜力。</p><h3 id="3论文2sk-vqa"><span class="mr-2">（3）论文2：SK-VQA</span><a href="#3论文2sk-vqa" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>SK-VQA: Synthetic Knowledge Generation at Scale for Training Context-Augmented Multimodal LLMs</p><p>情景增强的MLLM，具体创新是一种能够用于大规模收集自然和多样化数据。</p><p>没有依靠模板的方法（template-based methods）为真实数据构建QA对，就是利用GPT4来为给定图像生成相关上下文文档和多个问答对，以此创建了一个SK-VQA数据集（迄今为止最大的KBVQA数据集，包含超过200万个问答对）。</p><p>流程：</p><ol><li>数据集生成<li>图像参考(ImRef)过滤<li>上下文答案存在 (CAP) 过滤</ol><h3 id="4论文3r1-searcher"><span class="mr-2">（4）论文3：R1-Searcher</span><a href="#4论文3r1-searcher" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>R1-Searcher: Incentivizing the Search Capability in LLMs via Reinforcement Learning</p><p>核心思路：基于结果的两阶段强化学习方法，旨在增强LLMs的搜索能力。</p><p><strong>开源链接</strong>：</p><ul><li><p>代码仓库：https://github.com/SsmallSong/R1-Searcher</p><li><p>模型：</p><li><ul><li>Qwen-2.5-7B-Base-RAG-RL: https://huggingface.co/XXsongLALA/Qwen-2.5-7B-base-RAG-RL<li>Llama-3.1-8B-Instruct-RAG-RL: https://huggingface.co/XXsongLALA/Llama-3.1-8B-instruct-RAG-RL</ul><li>训练数据：https://huggingface.co/datasets/XXsongLALA/RAG-RL-Hotpotqa-with-2wiki</ul><p>我们使用两阶段结果监督强化学习，整体基于Reinforce++算法。在第一阶段，模型被训练以有效利用外部检索系统，在第二阶段，模型被训练在推理过程中整合检索，以准确解答问题。我们通过奖励设计实现两阶段训练：</p><ul><li>第一阶段，reward由retrieval-reward和format-reward组成，如果模型在推理过程中进行了检索，就会得到retrieval-reward，旨在让模型学会调用工具的格式；<li>第二阶段，retrieval-reward被替换为answer-reward，让模型更自由地进行探索，answer-reward是标准答案和预测答案的F1-Score，旨在让模型学会正确调用工具解决问题。</ul><p>另外，我们对Reinforce++算法进行了修改以适应检索增强生成场景。我们的目标是让模型在面对不确定性时能够自主获取外部知识，从而有效整合推理和检索。为了无缝整合检索到的文档并确保模型优化的合理性，我们对原始算法进行了两项改进：RAG-based Rollout和Retrieval Mask-based Loss Calculation：</p><ul><li>RAG-based Rollout： 我们使用标签<begin_of_query>...<end_of_query>来引导模型在生成过程中调用外部检索系统。捕捉到模型需要进行检索时，推理暂停并进行检索。检索到的文档被封装在<begin_of_documents>...<end_of_documents>标签中，并整合到模型的推理过程中。这种方法确保检索无缝融入推理过程，使模型能够基于检索到的文档继续推理，而不被打断。</end_of_documents></begin_of_documents></end_of_query></begin_of_query><li>Retrieval Mask-based Loss Calculation：当模型执行检索时，检索到的文档作为环境观察的一部分被整合到推理过程中。然而，模型并不需要自主生成这些文档。为了减少环境的影响，我们将<begin_of_documents>...<end_of_documents>指定为特殊标记，并在训练中对其进行掩码处理。这可以防止这些外部标记影响损失计算，确保检索到的文档不会干扰模型的内在推理和生成过程。</end_of_documents></begin_of_documents></ul><h2 id="实验结果"><span class="mr-2"><strong>实验结果</strong></span><a href="#实验结果" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>🚀 如下表所示，我们的方法R1-Searcher：</p><ul><li>在多跳问答任务上实现显著的性能提升：相比于最好的基线ReARTeR，R1-Searcher，使用相同的LLaMA-3.1-8B-Instruct作为backbone，实现了显著的性能提升：在HotpotQA上提升了<strong>48.2%</strong>，在2WikiMultiHopQA上提升了<strong>21.7%</strong>，在Bamboogle上提升了<strong>4.0%</strong>（LLM-as-Judge）。这表明我们的方法可以有效地促进模型在推理过程中进行准确的检索调用。<li>从基础LLM开始进行RL学习，无需冷启动：我们从头开始使用强大的基础模型（如Qwen-2.5-7B-Base）进行RL学习。令人惊讶的是，我们能够取得更好的结果，并在大多数领域内和领域外的数据集上获得最佳性能，甚至超过了闭源的LLM，如GPT-4o-mini。这些结果展示了我们的两阶段RL方法在指导LLMs学习过程中的有效性。<li>保持泛化能力：我们仅使用HotpotQA和2WikiMultiHopQA训练集中的8148个样本进行RL训练。该模型不仅在这些领域内数据集上表现出色，还在领域外数据集（如Musique和Bamboogle）上展示了强大的泛化能力。这表明模型通过在RL训练期间的探索，有效地学习了检索并将其与推理相结合，从而在需要检索的新测试数据集上实现稳健的性能。<img data-src="https://mmbiz.qpic.cn/mmbiz_png/G7ia3FZ0o0OowFv80G6bBpr2WPtLjaNKkcYNVbCE3j3ZkAKJcVusiardo8yhmQT010rb6sZKNRvI6qPghTE4DwLA/640?wx_fmt=png&amp;from=appmsg" alt="img" data-proofer-ignore></ul><p>另外，为了评估模型对于联网搜索泛化能力，我们在最新提出的Bamboogle任务上进行联网搜索的测试，这种设定在RL训练期间并未遇到。如下图所示，我们的模型相较于使用相同Qwen-2.5-7B-Base作为backbone的本地检索系统，性能提升了18.2%。此外，与使用相同在线搜索但骨干模型更大的32B的Search-o1相比，我们的模型性能提升了11.4%。这表明我们的模型能够适应在线搜索场景，并且R1-Searcher使模型能够在推理过程中检索信息，而不仅仅是记忆响应格式。</p><p><img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/G7ia3FZ0o0OowFv80G6bBpr2WPtLjaNKkA6Q7oIlofAibeVYdicyOibk4acPqywHcyJ93y6mMZFqAMB2rsX2LoHJDg/640?wx_fmt=jpeg&amp;from=appmsg" alt="img" data-proofer-ignore></p><p>我们针对以下问题进行了更详细的实验和分析，完整的分析请看原论文：</p><ol><li>GRPO和Reinforce++算法的比较</ol><ul><li>结论：GRPO的生成solution更长和检索频率更高。GRPO在领域外测试数据集（如Bamboogle）上也展现出更好的性能；而Reinforce++在领域内测试集（如HotpotQA和2Wiki）上表现更优。</ul><ol><li>RL和SFT的比较</ol><ul><li>结论：RL在领域内和领域外的测试集上均优于SFT。SFT能够帮助模型生成检索查询，但这些查询的时机和相关性不如通过RL训练生成的查询。</ul><ol><li>Reward的设计对训练的影响</ol><ul><li>结论：基于F1的答案奖励能够产生更长的回答长度和更优的最终结果；基于EM的奖励在训练过程中导致回答长度较短，并且在测试时表现不如基于CEM或F1的奖励；基于CEM的奖励会生成带有不必要信息的偏长的answer。</ul><ol><li>数据难度分布和数据多样性对训练的影响</ol><ul><li>结论：使用混合数据集训练的模型在检索次数和生成回答长度上都有所增加，并且在测试集上取得了更高的分数；训练数据中混入较高难度的数据可以在领域内和领域外的测试集上均取得更好的效果。</ul><p><img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/G7ia3FZ0o0OowFv80G6bBpr2WPtLjaNKkH0sP0Cicia9oZHjMAYCxIwt87NicLSbO3kichfhJObLJdyV6dB62XMR42g/640?wx_fmt=jpeg&amp;from=appmsg" alt="img" data-proofer-ignore></p><p><img data-src="https://mmbiz.qpic.cn/mmbiz_jpg/G7ia3FZ0o0OowFv80G6bBpr2WPtLjaNKkn9uNKHFGpOqjL8iaNg3iaXQocGe68FoaToORaOYHwiaFPOtViaeaxq7lAQ/640?wx_fmt=jpeg&amp;from=appmsg" alt="img" data-proofer-ignore></p><h2 id="案例展示"><span class="mr-2"><strong>案例展示</strong></span><a href="#案例展示" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><img data-src="https://mmbiz.qpic.cn/mmbiz_png/G7ia3FZ0o0OowFv80G6bBpr2WPtLjaNKkMYBrFibS2MMichA8qQfg4icYmnqBRtSXQjiaaPawW6RF3UVUhIwyuuKtYw/640?wx_fmt=png&amp;from=appmsg" alt="img" data-proofer-ignore></p><h2 id="idea"><span class="mr-2">Idea</span><a href="#idea" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>由于计算资源有限，就在别人训练好的模型（比如Qwen2-VL）的基础上用DQN/PPO微调，强化学习用的数据集就是DocVQA这种常见的多模态测试数据集，DocVQA数据集中的标准答案就当作是反馈（如果MLLM生成的responce和这个答案一致就点赞，否则就纠正），query就是查询，image就是图像。</p><h3 id="可行性分析"><span class="mr-2">可行性分析</span><a href="#可行性分析" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ol><li><strong>基础模型选择</strong>：选择一个性能优越的预训练模型作为起点，可以大大减少所需的计算资源，并缩短开发周期。Qwen2-VL这样的多模态模型能够很好地理解文本和图像信息，为后续的任务提供了坚实的基础。<li><strong>数据集选择</strong>：DocVQA是一个非常适合用于此目的的数据集，它包含了大量文档图像及其对应的问题与答案，有助于训练模型准确理解和回答基于图像的问题。<li><strong>反馈机制设计</strong>：将DocVQA中的标准答案用作反馈信号，通过比较生成的回答与标准答案的一致性来提供奖励（点赞或纠正），这种方法直观有效。这不仅简化了奖励函数的设计，还确保了反馈的质量。</ol><h3 id="实施建议"><span class="mr-2">实施建议</span><a href="#实施建议" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ol><li><strong>环境设置</strong>：<ul><li><strong>状态空间</strong>：定义状态空间为当前查询、图像以及模型生成的回答。<li><strong>动作空间</strong>：动作空间可以是模型参数的调整方向和幅度，或者是直接对回答进行修正的选择。</ul><li><strong>强化学习算法选择</strong>：<ul><li><strong>PPO</strong>可能更适合这种场景，因为它在处理高维状态和动作空间时表现良好，并且能更稳定地更新策略，避免了DQN中可能出现的过估计问题。</ul><li><strong>奖励设计</strong>：<ul><li>除了简单的“点赞/纠正”之外，还可以考虑引入部分奖励机制，即即使回答不完全正确，但如果包含了正确的关键信息，也可以给予一定的正向激励。<li>对于纠正的情况，可以尝试给出具体的修改建议，而不是仅仅标记为错误，这样可以帮助模型更快地学习到正确的模式。</ul><li><strong>实验与评估</strong>：<ul><li>在开始全面训练之前，先在一个较小规模的数据子集上进行初步实验，以验证整个框架的有效性。<li>使用交叉验证等技术评估模型性能，确保改进措施确实提升了模型的整体表现。</ul><li><strong>持续优化</strong>：<ul><li>根据实验结果不断调整强化学习策略和参数设置，逐步逼近最优解。<li>考虑引入用户实际交互数据，进一步丰富训练样本，提升模型的实际应用效果。</ul></ol></div><div class="post-tail-wrapper text-muted"><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> 本文由作者按照 <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> 进行授权</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">分享</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AE%9E%E9%AA%8C+-+zoe+Chen&url=https%3A%2F%2Fzoechen119.github.io%2Fposts%2F%25E5%25A4%259A%25E6%25A8%25A1%25E6%2580%2581%25E5%25AE%259E%25E9%25AA%258C%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AE%9E%E9%AA%8C+-+zoe+Chen&u=https%3A%2F%2Fzoechen119.github.io%2Fposts%2F%25E5%25A4%259A%25E6%25A8%25A1%25E6%2580%2581%25E5%25AE%259E%25E9%25AA%258C%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fzoechen119.github.io%2Fposts%2F%25E5%25A4%259A%25E6%25A8%25A1%25E6%2580%2581%25E5%25AE%259E%25E9%25AA%258C%2F&text=%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AE%9E%E9%AA%8C+-+zoe+Chen" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="分享链接" data-title-succeed="链接已复制！"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">最近更新</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/C25_11%E5%85%A5%E9%97%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%860/">【NLP入门趣味题】肉眼找朋友</a><li><a href="/posts/C25_11%E5%85%A5%E9%97%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%861/">【NLP入门趣味题】探索语言模型与词向量</a><li><a href="/posts/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/">强化学习</a><li><a href="/posts/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AE%9E%E9%AA%8C/">多模态实验</a><li><a href="/posts/%E5%A4%9A%E6%A8%A1%E6%80%81RAG/">多模态rag</a></ul></div><div id="access-tags"><div class="panel-heading">热门标签</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/nlp/">nlp</a> <a class="post-tag" href="/tags/%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/">技术综述</a> <a class="post-tag" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a> <a class="post-tag" href="/tags/rag/">RAG</a> <a class="post-tag" href="/tags/%E8%AF%AD%E8%A8%80%E5%AD%A6/">语言学</a> <a class="post-tag" href="/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/">预训练模型</a> <a class="post-tag" href="/tags/bert/">BERT</a> <a class="post-tag" href="/tags/courses/">Courses</a> <a class="post-tag" href="/tags/chatgpt/">ChatGPT</a> <a class="post-tag" href="/tags/mamba/">Mamba</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">文章内容</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>相关文章</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/C25_11%E5%85%A5%E9%97%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%861/"><div class="card-body"> <em class="small" data-ts="1746514856" data-df="YYYY-MM-DD" > 2025-05-06 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>【NLP入门趣味题】探索语言模型与词向量</h3><div class="text-muted small"><p> 【NLP入门趣味题】探索语言模型与词向量 题目名称： “猜猜我是谁？——用词向量玩文字游戏” 🎯 任务目标 理解语言模型（Language Model）的基本概念——它能预测下一个词是什么！ 认识词向量（Word Embedding）——让计算机”看懂”词语的数学表达。 通过简单代码体验语义相似度，感受AI如何理解词语关系。 🔍 题目内容 假设你有一个超级简单的...</p></div></div></a></div><div class="card"> <a href="/posts/C25_11%E5%85%A5%E9%97%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%860/"><div class="card-body"> <em class="small" data-ts="1745910056" data-df="YYYY-MM-DD" > 2025-04-29 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>【NLP入门趣味题】肉眼找朋友</h3><div class="text-muted small"><p> 【NLP入门趣味题】肉眼找朋友 ❓ 问题1：肉眼找朋友 观察坐标，回答以下问题（无需计算）： “国王” 和 “王后” 的距离近，还是 “苹果” 和 “香蕉” 的距离近？ 如果 “国王” 的坐标是 (1, 0)，你觉得 “王子” 的坐标可能是？ A. (0.8, 0.2) B. (0, 0.8) 💡 提示：第一个数字代表...</p></div></div></a></div><div class="card"> <a href="/posts/PaperNote_ColPali/"><div class="card-body"> <em class="small" data-ts="1735574400" data-df="YYYY-MM-DD" > 2024-12-31 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Papernote_colpali</h3><div class="text-muted small"><p> ColPali: Efficient Document Retrieval with Vision Language Models 摘要 本文针对的研究领域是“视觉丰富的文档检索系统”，本文对这个领域进行了基准测试进而提出了视觉文档检索基准ViDoRe。 ViDoRe由跨越多个领域、语言和设置的各种页面级检索任务组成。 本文提出了新的检索模型架构ColPali，核心思想是利用...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/PaperNote_ColPali/" class="btn btn-outline-primary" prompt="上一篇"><p>Papernote_colpali</p></a> <a href="/posts/C25_11%E5%85%A5%E9%97%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%860/" class="btn btn-outline-primary" prompt="下一篇"><p>【NLP入门趣味题】肉眼找朋友</p></a></div><script src="https://utteranc.es/client.js" repo="zoeChen119/zoeChen119.github.io" issue-term="title" crossorigin="anonymous" async> </script> <script type="text/javascript"> $(function() { const origin = "https://utteranc.es"; const iframe = "iframe.utterances-frame"; const lightTheme = "github-light"; const darkTheme = "github-dark"; let initTheme = lightTheme; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches)) { initTheme = darkTheme; } addEventListener("message", (event) => { let theme; /* credit to <https://github.com/utterance/utterances/issues/170#issuecomment-594036347> */ if (event.origin === origin) { /* page initial */ theme = initTheme; } else if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { /* global theme mode changed */ const mode = event.data.message; theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme); } else { return; } const message = { type: "set-theme", theme: theme }; const utterances = document.querySelector(iframe).contentWindow; utterances.postMessage(message, origin); }); }); </script></div></div><footer class="row pl-3 pr-3"><div class="col-12 d-flex justify-content-between align-items-center text-muted pl-0 pr-0"><div class="footer-left"><p class="mb-0"> © 2025 <a href="https://github.com/zoeChen119">陈政伊</a>. <span data-toggle="tooltip" data-placement="top" title="除非另有说明，本网站上的博客文章均由作者按照知识共享署名 4.0 国际 (CC BY 4.0) 许可协议进行授权。">保留部分权利。</span></p></div><div class="footer-right"><p class="mb-0"> 本站由 <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> 生成，采用 <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> 主题。</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">热门标签</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/nlp/">nlp</a> <a class="post-tag" href="/tags/%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/">技术综述</a> <a class="post-tag" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a> <a class="post-tag" href="/tags/rag/">RAG</a> <a class="post-tag" href="/tags/%E8%AF%AD%E8%A8%80%E5%AD%A6/">语言学</a> <a class="post-tag" href="/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/">预训练模型</a> <a class="post-tag" href="/tags/bert/">BERT</a> <a class="post-tag" href="/tags/courses/">Courses</a> <a class="post-tag" href="/tags/chatgpt/">ChatGPT</a> <a class="post-tag" href="/tags/mamba/">Mamba</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">发现新版本的内容。</p><button type="button" class="btn btn-primary" aria-label="Update"> 更新 </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">搜索结果为空</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/zh.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
