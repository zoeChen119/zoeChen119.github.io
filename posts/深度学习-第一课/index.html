<!DOCTYPE html><html lang="zh-CN" data-mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="深度学习 第一课" /><meta property="og:locale" content="zh_CN" /><meta name="description" content="Course 1：" /><meta property="og:description" content="Course 1：" /><link rel="canonical" href="https://zoechen119.github.io/posts/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%AC%AC%E4%B8%80%E8%AF%BE/" /><meta property="og:url" content="https://zoechen119.github.io/posts/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%AC%AC%E4%B8%80%E8%AF%BE/" /><meta property="og:site_name" content="zoe Chen" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2024-12-16T00:00:00+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="深度学习 第一课" /><meta name="twitter:site" content="@twitter_username" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-12-20T08:50:14+08:00","datePublished":"2024-12-16T00:00:00+08:00","description":"Course 1：","headline":"深度学习 第一课","mainEntityOfPage":{"@type":"WebPage","@id":"https://zoechen119.github.io/posts/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%AC%AC%E4%B8%80%E8%AF%BE/"},"url":"https://zoechen119.github.io/posts/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%AC%AC%E4%B8%80%E8%AF%BE/"}</script><title>深度学习 第一课 | zoe Chen</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="zoe Chen"><meta name="application-name" content="zoe Chen"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="/assets/img/avatar.jfif" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">zoe Chen</a></div><div class="site-subtitle font-italic">nlper, dler, sims4er</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>首页</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>分类</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>标签</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>归档</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>关于</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/zoeChen119" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['zoe9698','163.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> 首页 </a> </span> <span>深度学习 第一课</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> 文章</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="搜索..."> </span> <span id="search-cancel" >取消</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>深度学习 第一课</h1><div class="post-meta text-muted"> <span> 发表于 <em class="" data-ts="1734278400" data-df="YYYY-MM-DD" data-toggle="tooltip" data-placement="bottom"> 2024-12-16 </em> </span> <span> 更新于 <em class="" data-ts="1734655814" data-df="YYYY-MM-DD" data-toggle="tooltip" data-placement="bottom"> 2024-12-20 </em> </span><div class="d-flex justify-content-between"> <span> 作者 <em> <a href="https://github.com/zoeChen119">陈政伊</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3688 字"> <em>20 分钟</em>阅读</span></div></div></div><div class="post-content"><h1 id="course-1">Course 1：</h1><h2 id="part-1人工智能基础常识"><span class="mr-2">Part 1：人工智能基础常识</span><a href="#part-1人工智能基础常识" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="什么是监督学习"><span class="mr-2">什么是监督学习？</span><a href="#什么是监督学习" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><strong>监督学习需要有明确的目标，很清楚自己想要什么结果</strong>。比如：按照“既定规则”来分类、预测某个具体的值…</p><p>监督并不是指人站在机器旁边看机器做的对不对，而是下面的流程：</p><ol><li><p>选择一个适合目标任务的数学模型</p><li><p>先把一部分已知的“问题和答案”（训练集）给机器去学习</p><li><p>机器总结出了自己的“方法论”</p><li><p>人类把”新的问题”（测试集）给机器，让他去解答</p><p><img data-src="../../../assets/img/2024-12-16-深度学习-第一课/image-20241216153112249.png" alt="image-20241216153112249" data-proofer-ignore></p></ol><p>上面提到的问题和答案只是一个比喻，假如我们想要完成文章分类的任务，则是下面的方式：</p><ol><li>选择一个合适的数学模型<li>把一堆已经分好类的文章和<strong>他们的分类</strong>给机器<li>机器学会了分类的“方法论”<li>机器学会后，再丢给他一些新的文章（不带分类），让机器预测这些文章的分类</ol><p><strong>常见的监督学习算法</strong></p><p><img data-src="../../../assets/img/2024-12-16-深度学习-第一课/image-20241216153914358.png" alt="image-20241216153914358" data-proofer-ignore></p><h4 id="分类算法是一类监督学习算法"><span class="mr-2">分类算法是一类监督学习算法</span><a href="#分类算法是一类监督学习算法" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><strong>监督学习</strong>分为两大类任务</p><p>​ <strong>回归：预测连续的、具体的数值。</strong></p><p>​ <strong>分类：对各种事物分门别类，用于离散型预测。</strong></p><p><img data-src="../../../assets/img/2024-12-16-深度学习-第一课/image-20241216153334472.png" alt="image-20241216153334472" data-proofer-ignore></p><blockquote><p>连续：</p><p>当我们说某个量是连续的，意味着它可以在一定范围内取任意值。</p><p>例如，人的身高、物体的重量或时间都是连续变量的例子，因为它们可以取无限多的值，并且两个值之间的差异可以非常小。</p><p>在数学上，如果一个变量可以在实数线上自由变动，那么这个变量就是连续的。</p><p>离散：</p><p>相对地，离散指的是那些只能取特定、分离值的数据类型。离散变量具有明确的、可数的不同状态或类别。</p><p>比如骰子的结果（1到6）、硬币投掷的结果（正面或反面），或者一个人的血型（A, B, AB, O）。</p></blockquote><h3 id="什么是无监督学习"><span class="mr-2">什么是无监督学习？</span><a href="#什么是无监督学习" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><strong>无监督学习是一种机器学习的训练方式，它本质上是一个统计手段，在没有标签的数据里可以发现潜在的一些结构的一种训练方式。</strong></p><p>它主要具备3个特点：</p><ol><li>无监督学习没有明确的目的<li>无监督学习不需要给数据打标签<li>无监督学习无法量化效果</ol><h4 id="聚类算法是一类无监督学习算法"><span class="mr-2">聚类算法是一类无监督学习算法</span><a href="#聚类算法是一类无监督学习算法" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>分类算法需要事先知道“类别”个数，如果“类别”个数无从得知，如何给一堆数据分类呢？</p><p>聚类：简单说就是一种自动分类的方法，在监督学习中，你很清楚每一个分类是什么，但是聚类则不是，你并不清楚聚类后的几个分类每个代表什么意思。</p><p><strong>常见的无监督学习算法</strong></p><p><img data-src="../../../assets/img/2024-12-16-深度学习-第一课/image-20241217122318034.png" alt="image-20241217122318034" data-proofer-ignore></p><h3 id="什么是深度学习"><span class="mr-2">什么是深度学习？</span><a href="#什么是深度学习" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><h4 id="神经网络深度学习"><span class="mr-2">神经网络≈深度学习</span><a href="#神经网络深度学习" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>深度学习的概念源于人工神经网络的研究，但是并不完全等于传统神经网络。</p><p>不过在叫法上，很多深度学习算法中都会包含”神经网络”这个词，比如：卷积神经网络、循环神经网络。</p><p><img data-src="../../../assets/img/2024-12-16-深度学习-第一课/image-20241216162656500.png" alt="image-20241216162656500" data-proofer-ignore></p><p><img data-src="../../../assets/img/2024-12-16-深度学习-第一课/image-20241216162718139.png" alt="image-20241216162718139" data-proofer-ignore></p><p>模拟人的大脑，造出可以思考的机器。人为什么能够思考？原因在于人体的神经网络。</p><blockquote><ol><li>外部刺激通过神经末梢，转化为电信号，转导到神经细胞（又叫神经元）。<li>无数神经元构成神经中枢。<li>神经中枢综合各种信号，做出判断。<li>人体根据神经中枢的指令，对外部刺激做出反应。</ol></blockquote><p>既然思考的基础是神经元，如果能够”人造神经元”（artificial neuron），就能组成人工神经网络，模拟思考。上个世纪六十年代，提出了最早的”人造神经元”模型，叫做<a href="https://zh.wikipedia.org/wiki/感知器">“感知器”</a>（perceptron），直到今天还在用。</p><p><img data-src="../../../assets/img/2024-12-16-深度学习-第一课/image-20241216162837425.png" alt="image-20241216162837425" data-proofer-ignore></p><p>上图的圆圈就代表一个感知器。它接受多个输入（x1，x2，x3…），产生一个输出（output），好比神经末梢感受各种外部环境的变化，最后产生电信号。</p><p>举个例子：城里正在举办一年一度的游戏动漫展览，小明拿不定主意，周末要不要去参观。他决定考虑三个因素：</p><blockquote><ol><li>天气：周末是否晴天？<li>同伴：能否找到人一起去？<li>价格：门票是否可承受？</ol></blockquote><p>这就构成一个感知器。上面三个因素就是外部输入，最后的决定就是感知器的输出。如果三个因素都是 Yes（使用<code class="language-plaintext highlighter-rouge">1</code>表示），输出就是1（去参观）；如果都是 No（使用<code class="language-plaintext highlighter-rouge">0</code>表示），输出就是0（不去参观）。</p><p><strong>如果某些因素成立，另一些因素不成立，输出是什么？比如，周末是好天气，门票也不贵，但是小明找不到同伴，他还要不要去参观呢？</strong></p><p>现实中，各种因素很少具有同等重要性：某些因素是决定性因素，另一些因素是次要因素。因此，可以给这些因素指定权重（weight），代表它们不同的重要性。</p><blockquote><ul><li>天气：权重为8<li>同伴：权重为4<li>价格：权重为4</ul></blockquote><p>上面的权重表示，天气是决定性因素，同伴和价格都是次要因素。</p><p>如果三个因素都为1，它们乘以权重的总和就是 8 + 4 + 4 = 16。如果天气和价格因素为1，同伴因素为0，总和就变为 8 + 0 + 4 = 12。</p><p>这时，还需要指定一个阈值（threshold）。如果总和大于阈值，感知器输出1，否则输出0。假定阈值为8，那么 12 &gt; 8，小明决定去参观。阈值的高低代表了意愿的强烈，阈值越低就表示越想去，越高就越不想去。</p><p>上面的决策过程，使用数学表达如下。</p><p><img data-src="../../../assets/img/2024-12-16-深度学习-第一课/image-20241216163526776.png" alt="image-20241216163526776" data-proofer-ignore></p><p>上面公式中，<code class="language-plaintext highlighter-rouge">x</code>表示各种外部因素，<code class="language-plaintext highlighter-rouge">w</code>表示对应的权重。</p><p>真实世界中，实际的决策模型则要复杂得多，是由多个感知器组成的多层网络。</p><p><img data-src="../../../assets/img/2024-12-16-深度学习-第一课/image-20241216163624831.png" alt="image-20241216163624831" data-proofer-ignore></p><h2 id="part-2如何训练一个人工智能模型"><span class="mr-2">Part 2：如何训练一个人工智能模型</span><a href="#part-2如何训练一个人工智能模型" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="20-神经网络的运作过程"><span class="mr-2">2.0 神经网络的运作过程</span><a href="#20-神经网络的运作过程" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>一个神经网络的搭建，需要满足三个条件。</p><blockquote><ul><li>输入和输出<li>权重（<code class="language-plaintext highlighter-rouge">w</code>）和阈值（<code class="language-plaintext highlighter-rouge">b</code>）<li>多层感知器的结构</ul></blockquote><p>也就是说需要先构建上面那个图的结构，其中，<strong>最困难的部分就是确定权重（<code class="language-plaintext highlighter-rouge">w</code>）和阈值（<code class="language-plaintext highlighter-rouge">b</code>）。目前为止，这两个值都是主观给出的，但现实中很难估计它们的值，必需有一种方法，可以自动计算出它们</strong>。</p><p><strong>:star: 试错法</strong>：先随机初始化它们的值，控制变量法保持其他参数都不变，<code class="language-plaintext highlighter-rouge">w</code>（或<code class="language-plaintext highlighter-rouge">b</code>）的微小变动，记作<code class="language-plaintext highlighter-rouge">Δw</code>（或<code class="language-plaintext highlighter-rouge">Δb</code>），然后观察输出有什么变化。不断重复这个过程，直至得到对应最精确输出的那组<code class="language-plaintext highlighter-rouge">w</code>和<code class="language-plaintext highlighter-rouge">b</code>，就是我们要的值。这个过程称为模型的训练。</p><p><strong>神经网络的运作过程：</strong></p><ol><li><strong>确定输入和输出</strong><li><strong>找到一种或多种算法，可以从输入得到输出</strong><li><strong>找到一组已知答案的数据集，用来训练模型，估算<code class="language-plaintext highlighter-rouge">w</code>和<code class="language-plaintext highlighter-rouge">b</code></strong><li><strong>一旦新的数据产生，输入模型，就可以得到结果，同时对<code class="language-plaintext highlighter-rouge">w</code>和<code class="language-plaintext highlighter-rouge">b</code>进行校正</strong></ol><center><font color="blue" size="6">数据集→训练阶段→测试阶段</font></center><h3 id="21-实例-手写数字识别"><span class="mr-2">2.1 实例-手写数字识别</span><a href="#21-实例-手写数字识别" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><img data-src="../../../assets/img/2024-12-16-深度学习-第一课/image-20241217122256287.png" alt="image-20241217122256287" data-proofer-ignore></p><p><img data-src="../../../assets/img/2024-12-16-深度学习-第一课/image-20241217121838059.gif" alt="image-20241217121838064" data-proofer-ignore></p><ul><li><p>灰度图像：其每一个像素值的范围是0~255（由纯黑色到纯白色），表示其颜色强弱程度。</p><li>黑白图像：每个像素值要么是0（表示纯黑色），要么是255（表示纯白色）。<li>RGB图像：有三个通道，分别是红色、绿色、蓝色。每个通道的每个像素值的范围也是0~255，表示其每个像素的颜色强弱。</ul><blockquote><p>通常处理的基本都是灰度图像，因为比较好操作（值范围较小，颜色较单一），有些RGB图像在输入给神经网络之前也被转化为灰度图像，也是为了方便计算，否则三个通道的像素一起处理计算量非常大。</p></blockquote><p><strong>第一层-输入层：将图像转换为其对应的由像素值构成的二维矩阵</strong></p><p><strong>第二层-卷积层：用来提取图像的底层特征</strong></p><p><img data-src="../../../assets/img/2024-12-16-深度学习-第一课/image-20241217121838060.gif" alt="image-20241217121838064" data-proofer-ignore></p><p>卷积（convolution）是CNN的核心操作，它是一种数学操作，用于将一张图像与另一张滤波器/卷积核（kernel）进行乘积运算，从而生成一张新的图像。滤波器是一种小尺寸的矩阵，通常用于提取图像中的特定特征，每个卷积核是独立学习的，它们可以捕捉到输入图像的不同特征。。卷积操作可以帮助提取图像中的有用信息，同时减少噪声和不必要的细节。</p><blockquote><p>卷积核个数=卷积层生成的特征图个数</p><p>较小的内核（如3x3或5x5）通常能够捕捉更精细的特征，而较大的内核可能会捕捉到更广泛但更模糊的模式。</p></blockquote><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> 
                                 <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> 
                                 <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> 
                                 <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> 
                                 <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
                          		<span class="p">)</span>
         <span class="p">)</span> <span class="c1">#添加卷积层
</span></pre></table></code></div></div><ul><li><code class="language-plaintext highlighter-rouge">padding='same'</code>: 这个参数控制了如何处理输入的边界。当你使用 <code class="language-plaintext highlighter-rouge">'same'</code> 时，它会在输入的边缘添加适当的零填充，<strong>以确保输出特征图的尺寸与输入尺寸相同（不考虑步幅的影响）</strong>。如果使用 <code class="language-plaintext highlighter-rouge">'valid'</code>，则不会进行填充，输出尺寸将会减小。<li><code class="language-plaintext highlighter-rouge">activation='relu'</code>: 激活函数应用于卷积操作后的输出。ReLU（Rectified Linear Unit）函数是深度学习中最常用的激活函数之一，它的公式是 f(x)=max⁡(0,x)<em>f</em>(<em>x</em>)=max(0,<em>x</em>)，它可以引入非线性，<strong>帮助模型学习复杂模式并缓解梯度消失问题</strong>。<li><code class="language-plaintext highlighter-rouge">input_shape=(28, 28, 3)</code>: 这个参数定义了输入到该层的数据的形状。对于二维卷积层来说，它应该是一个三元组 <code class="language-plaintext highlighter-rouge">(height, width, channels)</code>。在这个例子中，<code class="language-plaintext highlighter-rouge">28, 28</code> 是输入图像的高度和宽度，而 <code class="language-plaintext highlighter-rouge">3</code> 表示颜色通道的数量，即这是一个RGB图像（红、绿、蓝三个通道）。<strong>这是网络中第一个卷积层特有的参数，因为后续的卷积层可以从前一层自动推断输入形状</strong>。</ul><p><strong>第三层-池化层：防止过拟合，将数据维度减小</strong></p><p><img data-src="../../../assets/img/2024-12-16-深度学习-第一课/image-20241217121838064.png" alt="image-20241217121838064" data-proofer-ignore></p><p><strong>第四层-全连接层：汇总卷积层和池化层得到的图像的底层特征和信息</strong></p><p>将前一层的多为矩阵展开为一维的向量。</p><p><strong>第五层-输出层：根据全连接层的信息得到概率最大的结果</strong></p><p>通常也是一层全连接层。</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
</pre><td class="rouge-code"><pre><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span> <span class="p">)</span>  <span class="c1"># 创建sequential对象model 
</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> 
                                 <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> 
                                 <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> 
                                 <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> 
                                 <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
                          		<span class="p">)</span>
         <span class="p">)</span> <span class="c1">#添加卷积层1 
</span><span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">BatchNormalization</span><span class="p">())</span>    <span class="c1">#添加BN层1 
</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> 
                                 <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>         
                                 <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> 
                                 <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span>
                                <span class="p">)</span>
         <span class="p">)</span><span class="c1">#添加卷积层2 
</span><span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">BatchNormalization</span><span class="p">(</span> <span class="p">))</span>    <span class="c1">#添加BN层2 
</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> 
                                 <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                                 <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)</span>
         <span class="p">)</span>                     <span class="c1">#添加卷积层3 
</span><span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">BatchNormalization</span><span class="p">())</span>     <span class="c1">#添加BN层3 
</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> 
                                       <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
                                      <span class="p">)</span>
         <span class="p">)</span>     <span class="c1">#添加最大池化层1 
</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">())</span>                <span class="c1">#添加Flatten层 
</span><span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span> <span class="c1">#添加全连接层1
</span><span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span><span class="c1">#添加Dropout
</span><span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">))</span> <span class="c1">#添加输出层
</span></pre></table></code></div></div><p><img data-src="../../../assets/img/2024-12-16-深度学习-第一课/image-20241217121822562.png" alt="image-20241217121822562" data-proofer-ignore></p><h3 id="22-神经网络的补充知识"><span class="mr-2">2.2 神经网络的补充知识</span><a href="#22-神经网络的补充知识" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><h4 id="-batchnormalization层"><span class="mr-2">① BatchNormalization()层</span><a href="#-batchnormalization层" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><h4 id="-flatten层"><span class="mr-2">② Flatten层</span><a href="#-flatten层" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><h4 id="-dropout层"><span class="mr-2">③ Dropout层</span><a href="#-dropout层" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><h4 id="-激活函数"><span class="mr-2">④ 激活函数</span><a href="#-激活函数" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><h4 id="-优化器"><span class="mr-2">⑤ 优化器</span><a href="#-优化器" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><h4 id="-损失函数"><span class="mr-2">⑥ 损失函数</span><a href="#-损失函数" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><h4 id="-学习率"><span class="mr-2">⑦ 学习率</span><a href="#-学习率" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><h3 id="23-图像分类任务的模型调参技巧"><span class="mr-2">2.3 图像分类任务的模型调参技巧</span><a href="#23-图像分类任务的模型调参技巧" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><h3 id="24-数据增强方法"><span class="mr-2">2.4 数据增强方法</span><a href="#24-数据增强方法" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><h4 id="241-图像数据"><span class="mr-2">2.4.1 图像数据</span><a href="#241-图像数据" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><ol><li><strong>几何变换</strong>：<ul><li>旋转（Rotation）<li>平移（Translation）<li>缩放（Scaling）<li>翻转（Flipping）：水平或垂直<li>剪切（Shearing）</ul><li><strong>色彩变换</strong>：<ul><li>调整亮度（Brightness）<li>改变对比度（Contrast）<li>色调调整（Hue）<li>饱和度调整（Saturation）</ul><li><strong>噪声添加</strong>：<ul><li>添加高斯噪声<li>盐椒噪声</ul><li><strong>模糊和锐化</strong>：<ul><li>高斯模糊（Gaussian Blur）<li>中值模糊（Median Blur）</ul><li><strong>裁剪与填充</strong>（Cropping and Padding）<li><strong>随机擦除</strong>（Random Erasing）<li><strong>透视变换</strong>（Perspective Transform）<li><strong>混合（Mixup）</strong>：将两个图像及其标签按一定比例线性组合成新的训练样本。<li><strong>Cutmix</strong>：从一个图像中切割出一块区域，并用另一个随机选择的图像的相应块替换它。<li><strong>Mosaic Augmentation</strong>：将四个不同的图像拼接成一个新的图像作为输入。</ol><h4 id="242-文本数据"><span class="mr-2">2.4.2 文本数据</span><a href="#242-文本数据" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><ol><li><strong>同义词替换（Synonym Replacement, SR）</strong>：<ul><li>在句子中随机选择一些单词，并用它们的同义词替换。</ul><li><strong>随机插入（Random Insertion, RI）</strong>：<ul><li>在句子中随机位置插入一个随机选择的单词的同义词。</ul><li><strong>随机交换（Random Swap, RS）</strong>：<ul><li>随机交换句子中的两个单词的位置。</ul><li><strong>随机删除（Random Deletion, RD）</strong>：<ul><li>随机删除句子中的某些单词。</ul><li><strong>翻译后回译（Back Translation）</strong>：<ul><li>将文本翻译成另一种语言，再翻译回来以生成变体。</ul><li><strong>文本混洗（Text Shuffling）</strong>：<ul><li>打乱文档或段落的顺序，对于不依赖严格顺序的任务有效。</ul><li><strong>模板应用（Template Application）</strong>：<ul><li>使用预定义的句子结构模板生成新句子。</ul><li><strong>字符级扰动（Character-level Perturbation）</strong>：<ul><li>包括字符替换、插入、删除或交换，模仿打字错误等。</ul><li><strong>使用上下文感知的语言模型（Context-aware Language Models）</strong>：<ul><li>利用如BERT这样的预训练模型来生成相似但有差异的句子。</ul><li><strong>文本拼接（Concatenation）</strong>：<ul><li>将多个文本片段合并为一个更长的文本。</ul></ol></div><div class="post-tail-wrapper text-muted"><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> 本文由作者按照 <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> 进行授权</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">分享</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0+%E7%AC%AC%E4%B8%80%E8%AF%BE+-+zoe+Chen&url=https%3A%2F%2Fzoechen119.github.io%2Fposts%2F%25E6%25B7%25B1%25E5%25BA%25A6%25E5%25AD%25A6%25E4%25B9%25A0-%25E7%25AC%25AC%25E4%25B8%2580%25E8%25AF%25BE%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0+%E7%AC%AC%E4%B8%80%E8%AF%BE+-+zoe+Chen&u=https%3A%2F%2Fzoechen119.github.io%2Fposts%2F%25E6%25B7%25B1%25E5%25BA%25A6%25E5%25AD%25A6%25E4%25B9%25A0-%25E7%25AC%25AC%25E4%25B8%2580%25E8%25AF%25BE%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fzoechen119.github.io%2Fposts%2F%25E6%25B7%25B1%25E5%25BA%25A6%25E5%25AD%25A6%25E4%25B9%25A0-%25E7%25AC%25AC%25E4%25B8%2580%25E8%25AF%25BE%2F&text=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0+%E7%AC%AC%E4%B8%80%E8%AF%BE+-+zoe+Chen" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="分享链接" data-title-succeed="链接已复制！"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">最近更新</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/C25_11%E5%85%A5%E9%97%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%860/">【NLP入门趣味题】肉眼找朋友</a><li><a href="/posts/C25_11%E5%85%A5%E9%97%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%861/">【NLP入门趣味题】探索语言模型与词向量</a><li><a href="/posts/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/">强化学习</a><li><a href="/posts/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AE%9E%E9%AA%8C/">多模态实验</a><li><a href="/posts/%E5%A4%9A%E6%A8%A1%E6%80%81RAG/">多模态rag</a></ul></div><div id="access-tags"><div class="panel-heading">热门标签</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/nlp/">nlp</a> <a class="post-tag" href="/tags/%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/">技术综述</a> <a class="post-tag" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a> <a class="post-tag" href="/tags/rag/">RAG</a> <a class="post-tag" href="/tags/%E8%AF%AD%E8%A8%80%E5%AD%A6/">语言学</a> <a class="post-tag" href="/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/">预训练模型</a> <a class="post-tag" href="/tags/bert/">BERT</a> <a class="post-tag" href="/tags/courses/">Courses</a> <a class="post-tag" href="/tags/chatgpt/">ChatGPT</a> <a class="post-tag" href="/tags/mamba/">Mamba</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">文章内容</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>相关文章</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/C25_11%E5%85%A5%E9%97%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%861/"><div class="card-body"> <em class="small" data-ts="1746514856" data-df="YYYY-MM-DD" > 2025-05-06 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>【NLP入门趣味题】探索语言模型与词向量</h3><div class="text-muted small"><p> 【NLP入门趣味题】探索语言模型与词向量 题目名称： “猜猜我是谁？——用词向量玩文字游戏” 🎯 任务目标 理解语言模型（Language Model）的基本概念——它能预测下一个词是什么！ 认识词向量（Word Embedding）——让计算机”看懂”词语的数学表达。 通过简单代码体验语义相似度，感受AI如何理解词语关系。 🔍 题目内容 假设你有一个超级简单的...</p></div></div></a></div><div class="card"> <a href="/posts/C25_11%E5%85%A5%E9%97%A8%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%860/"><div class="card-body"> <em class="small" data-ts="1745910056" data-df="YYYY-MM-DD" > 2025-04-29 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>【NLP入门趣味题】肉眼找朋友</h3><div class="text-muted small"><p> 【NLP入门趣味题】肉眼找朋友 ❓ 问题1：肉眼找朋友 观察坐标，回答以下问题（无需计算）： “国王” 和 “王后” 的距离近，还是 “苹果” 和 “香蕉” 的距离近？ 如果 “国王” 的坐标是 (1, 0)，你觉得 “王子” 的坐标可能是？ A. (0.8, 0.2) B. (0, 0.8) 💡 提示：第一个数字代表...</p></div></div></a></div><div class="card"> <a href="/posts/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AE%9E%E9%AA%8C/"><div class="card-body"> <em class="small" data-ts="1739203200" data-df="YYYY-MM-DD" > 2025-02-11 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>多模态实验</h3><div class="text-muted small"><p> 多模态实验过程记录 实验1：colpaligemma-3b-pt-448-base测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/RAG/" class="btn btn-outline-primary" prompt="上一篇"><p>RAG</p></a> <a href="/posts/%E5%A4%9A%E6%A8%A1%E6%80%81RAG/" class="btn btn-outline-primary" prompt="下一篇"><p>多模态rag</p></a></div><script src="https://utteranc.es/client.js" repo="zoeChen119/zoeChen119.github.io" issue-term="title" crossorigin="anonymous" async> </script> <script type="text/javascript"> $(function() { const origin = "https://utteranc.es"; const iframe = "iframe.utterances-frame"; const lightTheme = "github-light"; const darkTheme = "github-dark"; let initTheme = lightTheme; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches)) { initTheme = darkTheme; } addEventListener("message", (event) => { let theme; /* credit to <https://github.com/utterance/utterances/issues/170#issuecomment-594036347> */ if (event.origin === origin) { /* page initial */ theme = initTheme; } else if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { /* global theme mode changed */ const mode = event.data.message; theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme); } else { return; } const message = { type: "set-theme", theme: theme }; const utterances = document.querySelector(iframe).contentWindow; utterances.postMessage(message, origin); }); }); </script></div></div><footer class="row pl-3 pr-3"><div class="col-12 d-flex justify-content-between align-items-center text-muted pl-0 pr-0"><div class="footer-left"><p class="mb-0"> © 2025 <a href="https://github.com/zoeChen119">陈政伊</a>. <span data-toggle="tooltip" data-placement="top" title="除非另有说明，本网站上的博客文章均由作者按照知识共享署名 4.0 国际 (CC BY 4.0) 许可协议进行授权。">保留部分权利。</span></p></div><div class="footer-right"><p class="mb-0"> 本站由 <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> 生成，采用 <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> 主题。</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">热门标签</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/nlp/">nlp</a> <a class="post-tag" href="/tags/%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/">技术综述</a> <a class="post-tag" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a> <a class="post-tag" href="/tags/rag/">RAG</a> <a class="post-tag" href="/tags/%E8%AF%AD%E8%A8%80%E5%AD%A6/">语言学</a> <a class="post-tag" href="/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/">预训练模型</a> <a class="post-tag" href="/tags/bert/">BERT</a> <a class="post-tag" href="/tags/courses/">Courses</a> <a class="post-tag" href="/tags/chatgpt/">ChatGPT</a> <a class="post-tag" href="/tags/mamba/">Mamba</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">发现新版本的内容。</p><button type="button" class="btn btn-primary" aria-label="Update"> 更新 </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">搜索结果为空</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/zh.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
